{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Vaccine Sentiment Classification\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook I ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8wlD1VRC3F",
        "outputId": "494e7951-f6af-4a17-b696-1826d561fe7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.10.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.11)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sB8j3615BTwM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import re\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import re\n",
        "import csv\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, accuracy_score\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from datasets import load_dataset\n",
        "import logging\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAyVZ0n9vIbG"
      },
      "source": [
        "## Use GPU for faster processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zeJXsqMvFAo",
        "outputId": "3209b032-bcf5-42df-806e-a416db199eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Available device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "## Upload dataset - Create and Clean dataframes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, dev_df = load_dataset('squad_v2', split=['train', 'validation'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "b82dc181120942e583db4f050d8dd142",
            "b10d8c298e67409fa4c197f1af9c0814",
            "34280b41890d49aea296724abd8a53a9",
            "6107c267b1a944d2a8d9e7210f226cc4",
            "4e8fec9abbf940ff850e440e6a9d86bf",
            "23098ad9b71b40f0813a4fbf851aa395",
            "d76c8eef67b34641b3989bfc4583fbd5",
            "332ffa12a93343ab8533559265c5b3cd",
            "75ab588c5a324715bdead5411fd5fdc0",
            "68be3b22ca0a4bae807fae91d970b45d",
            "b887740667254531b173008306dc5b68"
          ]
        },
        "id": "M28aYwiSWODa",
        "outputId": "be123d81-5e74-4a80-ef0c-6664ac2d2580"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b82dc181120942e583db4f050d8dd142",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train_df)\n",
        "dev_df = pd.DataFrame(dev_df)"
      ],
      "metadata": {
        "id": "v6fMTalfdfIO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MLSekm-spl7O"
      },
      "outputs": [],
      "source": [
        "# remove empty instances / duplicates / extra columns\n",
        "train_df.dropna(subset = [\"question\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"question\"], inplace=True)\n",
        "\n",
        "train_df.drop(['id'], axis = 1, inplace = True) \n",
        "train_df.drop(['title'], axis = 1, inplace = True) \n",
        "dev_df.drop(['id'], axis = 1, inplace = True) \n",
        "dev_df.drop(['title'], axis = 1, inplace = True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(df):\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  answer_start = []\n",
        "  answer_end = []\n",
        "  start = 0\n",
        "  end = 0\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    for a in row['answers']['text']:\n",
        "      context.append(row['context'])\n",
        "      question.append(row['question'])\n",
        "      answer.append(a)\n",
        "      text_length = len(a)\n",
        "      start_idx = row['answers']['answer_start'][0]\n",
        "      end_idx = row['answers']['answer_start'][0] + text_length\n",
        "      if (row['context'][start_idx:end_idx] == a):\n",
        "        answer_start.append(row['answers']['answer_start'][0])\n",
        "        answer_end.append(row['answers']['answer_start'][0] + text_length)\n",
        "      else:\n",
        "        for i in [1, 2]:\n",
        "          if row['context'][start_idx-i:end_idx-i] == a:\n",
        "              start = start_idx - i\n",
        "              end = end_idx - i\n",
        "        answer_start.append(start)\n",
        "        answer_end.append(end)\n",
        "\n",
        "  answer_dict = {'text': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n",
        "  dict = {'context': context, 'question': question, 'answer': answer_dict}  \n",
        "  #df = pd.DataFrame(dict)\n",
        "  return dict\n",
        "\n",
        "train_df = get_dataframe(train_df)\n",
        "dev_df = get_dataframe(dev_df)"
      ],
      "metadata": {
        "id": "TcB0mhFnn_dg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5I70w9IaQ5ym"
      },
      "outputs": [],
      "source": [
        "# remove special characters, urls, emojis and lowercase tweets\n",
        "# train_df[\"tweet\"] = train_df[\"tweet\"].apply(lambda line: re.sub('[^A-Za-z0-9]+', ' ', re.sub(r'http\\S+', ' ',line.lower().strip())))\n",
        "# dev_df[\"tweet\"] = dev_df[\"tweet\"].apply(lambda line: re.sub('[^A-Za-z0-9]+', ' ', re.sub(r'http\\S+', ' ',line.lower().strip())))\n",
        "# remove empty instances again\n",
        "# train_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "# dev_df.dropna(subset = [\"tweet\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OKStHo66Bz8t"
      },
      "outputs": [],
      "source": [
        "#print(train_df) # training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2W3hygNmB05X"
      },
      "outputs": [],
      "source": [
        "#print(dev_df) # validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Bert tokenizer and model"
      ],
      "metadata": {
        "id": "J0pyqUGe6pQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "#model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ],
      "metadata": {
        "id": "8kDVDFUd2IGt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training data\n",
        "context = train_df[\"context\"]\n",
        "question = train_df[\"question\"]\n",
        "answer = train_df[\"answer\"]\n",
        "answer_start = train_df[\"answer\"][\"answer_start\"]\n",
        "answer_end = train_df[\"answer\"][\"answer_end\"]\n",
        "\n",
        "encoding = tokenizer(question, context, \n",
        "                    truncation = True, \n",
        "                    padding = \"max_length\", \n",
        "                    max_length = 100,\n",
        "                    return_attention_mask = True)\n",
        "input_ids = encoding[\"input_ids\"] # token ids\n",
        "\n",
        "# validation data\n",
        "context_dev = dev_df[\"context\"]\n",
        "question_dev = dev_df[\"question\"]\n",
        "answer_dev = dev_df[\"answer\"]\n",
        "answer_start_dev = dev_df[\"answer\"][\"answer_start\"]\n",
        "answer_end_dev = dev_df[\"answer\"][\"answer_end\"]\n",
        "\n",
        "encoding_dev = tokenizer(question_dev, context_dev,\n",
        "                    truncation = True, \n",
        "                    padding = \"max_length\", \n",
        "                    max_length = 100,\n",
        "                    return_attention_mask = True)\n",
        "input_ids_dev = encoding_dev[\"input_ids\"] # token ids"
      ],
      "metadata": {
        "id": "qlKI9GTx6lE6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segment_ids(input_ids):\n",
        "  segments_ids = []\n",
        "  for i in input_ids: # for each list / instance\n",
        "    sep_index = i.index(tokenizer.sep_token_id)\n",
        "    num_seg_a = sep_index + 1\n",
        "    num_seg_b = len(i) - num_seg_a\n",
        "    ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "    segments_ids.append(ids)\n",
        "    assert len(ids) == len(i)\n",
        "  return segments_ids\n",
        "\n",
        "segments_ids = get_segment_ids(input_ids)\n",
        "segments_ids_dev = get_segment_ids(input_ids_dev)"
      ],
      "metadata": {
        "id": "DAqIjnFwYa7S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_positions(encoding, answer, answer_start, answer_end):\n",
        "    start_pos = []\n",
        "    end_pos = []\n",
        "    for i in range(len(answer[\"text\"])):\n",
        "        if (answer[\"text\"][i] == \"\"):\n",
        "           start_pos.append(0)\n",
        "           end_pos.append(0)\n",
        "           continue\n",
        "        start_pos.append(encoding.char_to_token(i, answer['answer_start'][i]))\n",
        "        end_pos.append(encoding.char_to_token(i, answer['answer_end'][i]))\n",
        "        if start_pos[-1] is None:\n",
        "          start_pos[-1] = tokenizer.model_max_length\n",
        "        if end_pos[-1] is None:\n",
        "          end_pos[-1] = encoding.char_to_token(i, answer['answer_end'][i] - 1)\n",
        "        if end_pos[-1] is None:\n",
        "          end_pos[-1] = tokenizer.model_max_length\n",
        "    return start_pos, end_pos\n",
        "\n",
        "start_pos, end_pos = add_token_positions(encoding, answer, answer_start, answer_end)\n",
        "encoding[\"start_positions\"] = start_pos\n",
        "encoding[\"end_positions\"] = end_pos\n",
        "start_pos_dev, end_pos_dev = add_token_positions(encoding_dev, answer_dev, answer_start_dev, answer_end_dev)\n",
        "encoding_dev[\"start_positions\"] = start_pos_dev\n",
        "encoding_dev[\"end_positions\"] = end_pos_dev"
      ],
      "metadata": {
        "id": "BmIuHi1lNRcj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # convert lists to tensors\n",
        "\n",
        "# train_inputs = torch.tensor(input_ids)\n",
        "# dev_inputs = torch.tensor(input_ids_dev)\n",
        "\n",
        "# train_masks = torch.tensor(segments_ids)\n",
        "# dev_masks = torch.tensor(segments_ids_dev)\n",
        "\n",
        "# train_answer_start = torch.tensor(start_pos)\n",
        "# dev_answer_start = torch.tensor(start_pos_dev)\n",
        "\n",
        "# train_answer_end = torch.tensor(end_pos)\n",
        "# dev_answer_end = torch.tensor(end_pos_dev)\n",
        "\n",
        "# # train_answers = torch.tensor(answer)\n",
        "# # dev_answers = torch.tensor(answer_dev)\n",
        "\n",
        "# # create datasets, dataloaders\n",
        "# BATCH_SIZE = 3\n",
        "# train_dataset = torch.utils.data.TensorDataset(train_inputs, train_masks, train_answer_start, train_answer_end)\n",
        "# train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# validation_dataset = torch.utils.data.TensorDataset(dev_inputs, dev_masks, dev_answer_start, dev_answer_end)\n",
        "# validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "_SklVyz4lBUf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(encoding)\n",
        "val_dataset = SquadDataset(encoding_dev)\n",
        "BATCH_SIZE = 2\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "1nBOISV3VKyI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "1OeqiS6QtA4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Hyperparameters\n",
        "learning_rate = 1e-5\n",
        "\n",
        "#Initialize optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)#, weight_decay=0.001)\n",
        "\n",
        "clip = 2\n",
        "\n",
        "#model"
      ],
      "metadata": {
        "id": "oDlxsbgwtAAN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h9hsKHAb_kH"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "\n",
        "for epoch in range(1):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "\n",
        "  # sets the mode to train\n",
        "  model.train()\n",
        "  for batch in train_dataloader:  # for every batch\n",
        "    inputs = batch['input_ids'].to(device)\n",
        "    masks = batch['attention_mask'].to(device)\n",
        "    start_pos = batch['start_positions'].to(device)\n",
        "    end_pos = batch['end_positions'].to(device)\n",
        "    if inputs.shape[0] == BATCH_SIZE:\n",
        "      y_pred = model(inputs, attention_mask=masks, start_positions=start_pos, end_positions=end_pos)\n",
        "      loss = y_pred[0]\n",
        "      #print(loss)\n",
        "\n",
        "      # answer_start = torch.argmax(start_scores)\n",
        "      # answer_end = torch.argmax(end_scores)\n",
        "      # for j in range(i, BATCH_SIZE):\n",
        "      #   answer = ' '.join(tokens[j][answer_start:answer_end+1])\n",
        "      #   print('Answer: \"' + answer + '\"')\n",
        "\n",
        "      #print(y_pred)\n",
        "      batch_losses.append(loss)\n",
        "      #Delete previously stored gradients\n",
        "      optimizer.zero_grad()\n",
        "      #Perform backpropagation starting from the loss calculated in this epoch\n",
        "      loss.backward()\n",
        "      #Perform gradient clipping to address exploding gradients\n",
        "      #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #Update model's weights based on the gradients calculated during backprop\n",
        "      optimizer.step()\n",
        "\n",
        "      # Total number of labels\n",
        "      #total += label.size(0)\n",
        "      # Total correct predictions\n",
        "      #_,pred_label = torch.max(y_pred[0], dim = 1)\n",
        "      #batch_acc += (pred_label == label).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    # sets the mode to testing\n",
        "    model.eval()\n",
        "    for batch in validation_dataloader:\n",
        "      inputs = batch['input_ids'].to(device)\n",
        "      masks = batch['attention_mask'].to(device)\n",
        "      start_pos = batch['start_positions'].to(device)\n",
        "      end_pos = batch['end_positions'].to(device)\n",
        "\n",
        "      if inputs.shape[0] == BATCH_SIZE:\n",
        "        y_dev_pred = model(inputs, attention_mask=masks, start_positions=start_pos, end_positions=end_pos) \n",
        "        loss_dev = y_dev_pred[0]\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        #total_dev += label.size(0)\n",
        "        # correct predictions\n",
        "        #_,pred_label = torch.max(y_dev_pred[0], dim = 1)  # get max probability\n",
        "        #batch_acc_dev += (pred_label == label).sum()\n",
        "\n",
        "\n",
        "  # accuracy = batch_acc/total\n",
        "  # accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_dataloader)\n",
        "  valid_loss = sum(batch_losses_dev)/len(validation_dataloader)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  # epoch_acc.append(accuracy)\n",
        "  # epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Validation Loss = {valid_loss:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB1TzI5D5kED"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U4iNgwizca5"
      },
      "outputs": [],
      "source": [
        "pred = []\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True)\n",
        "for (inputs, masks, label) in validation_dataloader:\n",
        "  inputs = inputs.to(device)\n",
        "  masks = masks.to(device)\n",
        "  label = label.to(device)\n",
        "  y_dev_pred = model(inputs, masks)\n",
        "  pred.append(y_dev_pred)\n",
        "\n",
        "# Compare predictions to actual labels\n",
        "print(classification_report(dev_labels, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iACQLKz_Xsw"
      },
      "outputs": [],
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "\n",
        "cm = confusion_matrix(label, y_dev_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfX_7laH5kEL"
      },
      "outputs": [],
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(label, y_dev_pred, average='weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC9lv2G45kEM"
      },
      "outputs": [],
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_loss(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq4J8TA45kEM"
      },
      "outputs": [],
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_acc(5)    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "squad (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b82dc181120942e583db4f050d8dd142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b10d8c298e67409fa4c197f1af9c0814",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34280b41890d49aea296724abd8a53a9",
              "IPY_MODEL_6107c267b1a944d2a8d9e7210f226cc4",
              "IPY_MODEL_4e8fec9abbf940ff850e440e6a9d86bf"
            ]
          }
        },
        "b10d8c298e67409fa4c197f1af9c0814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34280b41890d49aea296724abd8a53a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23098ad9b71b40f0813a4fbf851aa395",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d76c8eef67b34641b3989bfc4583fbd5"
          }
        },
        "6107c267b1a944d2a8d9e7210f226cc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_332ffa12a93343ab8533559265c5b3cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ab588c5a324715bdead5411fd5fdc0"
          }
        },
        "4e8fec9abbf940ff850e440e6a9d86bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68be3b22ca0a4bae807fae91d970b45d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  6.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b887740667254531b173008306dc5b68"
          }
        },
        "23098ad9b71b40f0813a4fbf851aa395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d76c8eef67b34641b3989bfc4583fbd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "332ffa12a93343ab8533559265c5b3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ab588c5a324715bdead5411fd5fdc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68be3b22ca0a4bae807fae91d970b45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b887740667254531b173008306dc5b68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}