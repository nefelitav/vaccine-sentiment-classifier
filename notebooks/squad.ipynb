{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Vaccine Sentiment Classification\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook I ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jl8wlD1VRC3F"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sB8j3615BTwM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import re\n",
        "import csv\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from datasets import load_dataset\n",
        "import logging\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAyVZ0n9vIbG"
      },
      "source": [
        "## Use GPU for faster processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zeJXsqMvFAo",
        "outputId": "0b4ff8eb-e82e-4116-c781-f310b250c04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Available device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "## Upload dataset - Create and Clean dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "17078ff067d045f7ba5bcd362f3878df",
            "8295ef7f4d1b435981d4b29653be5c6b",
            "e46e67e389d74ef89a44d9e3c0f7a702",
            "901b1411e59e4a08bf493514efe46fc6",
            "1ea0b5651ab74fa58766b126146ef868",
            "abdd4a1050414c5ebb03db240b7cbfd4",
            "058b7460c5d04a20bd0c7baaf5f3406b",
            "bdd4d30337f64abe92c3fed6ad46cfdf",
            "ef33c446085148639e02955751e9409c",
            "eb05010e58664763a2433b963f1e92d7",
            "56f172e75c5f404a91a0d27bf4e9314d"
          ]
        },
        "id": "M28aYwiSWODa",
        "outputId": "4e2afe12-e98e-4c53-c5ae-9d3079f7b1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17078ff067d045f7ba5bcd362f3878df",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_df, dev_df = load_dataset('squad_v2', split=['train', 'validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cUhbLBEpj-FC"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame(train_df)\n",
        "dev_df = pd.DataFrame(dev_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PA5rkJ9_OV-Z"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.iloc[0:10,:]\n",
        "dev_df = dev_df.iloc[0:10,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLSekm-spl7O"
      },
      "outputs": [],
      "source": [
        "# remove empty instances / duplicates / extra columns\n",
        "train_df.dropna(subset = [\"question\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"question\"], inplace=True)\n",
        "\n",
        "train_df.drop(['id'], axis = 1, inplace = True) \n",
        "train_df.drop(['title'], axis = 1, inplace = True) \n",
        "dev_df.drop(['id'], axis = 1, inplace = True) \n",
        "dev_df.drop(['title'], axis = 1, inplace = True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TcB0mhFnn_dg"
      },
      "outputs": [],
      "source": [
        "def get_data(df):\n",
        "\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  answer_start = []\n",
        "  answer_end = []\n",
        "  all_answers = []\n",
        "\n",
        "  for index, row in df.iterrows():                      # for each row - pair of question-answers\n",
        "    question.append(row['question'])\n",
        "    context.append(row['context'])\n",
        "    if row['answers']['text'] != []:\n",
        "      main_answer = row['answers']['text'][0]             # first answer\n",
        "      answer.append(main_answer)\n",
        "      all_answers.append(row['answers']['text'])          # save all plausible answers\n",
        "      text_length = len(main_answer)                      # length of main answer\n",
        "      start_idx = row['answers']['answer_start'][0]       # char where answer begins inside context\n",
        "      end_idx = start_idx + text_length                   # char where answer ends inside context\n",
        "      if end_idx >= len(row['context']):                  # out of range -> dont add in dataset\n",
        "        continue\n",
        "      if (row['context'][start_idx:end_idx] == main_answer):\n",
        "        answer_start.append(start_idx)\n",
        "        answer_end.append(end_idx)\n",
        "      else:\n",
        "        start = 0\n",
        "        end = 0\n",
        "        for i in [1, 2]:                                  # maybe the answer is off by one or two chars\n",
        "          if row['context'][start_idx-i:end_idx-i] == row['answers']['text'][0]:\n",
        "              start = start_idx - i\n",
        "              end = end_idx - i\n",
        "        answer_start.append(start)\n",
        "        answer_end.append(end)\n",
        "    else:\n",
        "      all_answers.append(None)\n",
        "      answer.append(None)\n",
        "      answer_start.append(None)\n",
        "      answer_end.append(None)\n",
        "\n",
        "  answer_dict = {'text': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n",
        "  dict = {'context': context, 'question': question, 'answer': answer_dict, 'all_answers': all_answers}  \n",
        "  return dict\n",
        "\n",
        "train_df = get_data(train_df)\n",
        "dev_df = get_data(dev_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0pyqUGe6pQQ"
      },
      "source": [
        "## Load Bert tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8kDVDFUd2IGt"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "#model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qlKI9GTx6lE6"
      },
      "outputs": [],
      "source": [
        "# training data\n",
        "encoding = tokenizer(train_df[\"context\"], train_df[\"question\"],\n",
        "                    truncation = True, \n",
        "                    padding = \"max_length\", \n",
        "                    max_length = 500,\n",
        "                    return_attention_mask = True)\n",
        "\n",
        "# validation data\n",
        "encoding_dev = tokenizer(dev_df[\"context\"], dev_df[\"question\"],\n",
        "                    truncation = True, \n",
        "                    padding = \"max_length\", \n",
        "                    max_length = 500,\n",
        "                    return_attention_mask = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Siq6XWC2NPmC"
      },
      "outputs": [],
      "source": [
        "tokens = []\n",
        "tokens_dev = []\n",
        "for inputs in encoding['input_ids']:\n",
        "  tokens.append(tokenizer.convert_ids_to_tokens(inputs))\n",
        "for inputs in encoding_dev['input_ids']:\n",
        "  tokens_dev.append(tokenizer.convert_ids_to_tokens(inputs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BmIuHi1lNRcj"
      },
      "outputs": [],
      "source": [
        "def add_token_positions(encoding, answer, answer_start, answer_end):\n",
        "    start = []\n",
        "    end = []\n",
        "    for i in range(len(answer[\"text\"])):\n",
        "      if (answer['answer_start'][i] == None):\n",
        "        start.append(None)\n",
        "        end.append(None)\n",
        "        continue\n",
        "      start.append(encoding.char_to_token(i, answer['answer_start'][i]))\n",
        "      end.append(encoding.char_to_token(i, answer['answer_end'][i]))\n",
        "      if start[-1] is None:\n",
        "        start[-1] = tokenizer.model_max_length\n",
        "      if end[-1] is None:\n",
        "        end[-1] = encoding.char_to_token(i, answer['answer_end'][i] - 1)\n",
        "      if end[-1] is None:\n",
        "        end[-1] = tokenizer.model_max_length\n",
        "    return start, end\n",
        "\n",
        "encoding['start_positions'], encoding['end_positions'] = add_token_positions(encoding, train_df[\"answer\"], train_df[\"answer\"][\"answer_start\"], train_df[\"answer\"][\"answer_end\"])\n",
        "encoding_dev['start_positions'], encoding_dev['end_positions']  = add_token_positions(encoding_dev,  dev_df[\"answer\"], dev_df[\"answer\"][\"answer_start\"], dev_df[\"answer\"][\"answer_end\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3cRBgVVRcvle"
      },
      "outputs": [],
      "source": [
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    dict = {}\n",
        "    for key, val in self.encodings.items():\n",
        "        if val[idx] == None:\n",
        "          dict[key] = torch.tensor(-1)\n",
        "        else:\n",
        "          dict[key] = torch.tensor(val[idx])\n",
        "    return dict\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)\n",
        "\n",
        "train_dataset = SquadDataset(encoding)\n",
        "validation_dataset = SquadDataset(encoding_dev)\n",
        "\n",
        "BATCH_SIZE = 10\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OeqiS6QtA4b"
      },
      "source": [
        "## Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oDlxsbgwtAAN"
      },
      "outputs": [],
      "source": [
        "#Define Hyperparameters\n",
        "learning_rate = 1e-5\n",
        "\n",
        "#Initialize optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)#, weight_decay=0.001)\n",
        "\n",
        "clip = 2\n",
        "\n",
        "#model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "raW-K-YBFcAi"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s):\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "    \n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h9hsKHAb_kH"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "\n",
        "for epoch in range(1):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  batch_losses_dev = []\n",
        "  batch_acc_dev = 0\n",
        "  exact_match = 0\n",
        "  f1_score = 0\n",
        "\n",
        "  # sets the mode to train\n",
        "  model.train()\n",
        "  for batch in train_dataloader:  # for every batch\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "    output = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, start_positions=start_positions, end_positions=end_positions)\n",
        "    \n",
        "    loss = output[0]\n",
        "    loss.backward()\n",
        "    batch_losses.append(loss)\n",
        "    optimizer.zero_grad()\n",
        "    #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    # Total number of labels\n",
        "    total += input_ids.size(0)\n",
        "    break\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "\n",
        "    # sets the mode to testing\n",
        "    model.eval()\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      token_type_ids = batch['token_type_ids'].to(device)\n",
        "      start_positions = batch['start_positions'].to(device)\n",
        "      end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "      start_logits, end_logits =  model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=False) \n",
        "\n",
        "      start_logits = start_logits.detach().cpu()\n",
        "      end_logits = end_logits.detach().cpu()\n",
        "\n",
        "      # number of labels\n",
        "      total_dev += input_ids.size(0)\n",
        "\n",
        "      # correct predictions\n",
        "      for idx, (start, end) in enumerate(zip(start_logits, end_logits)):\n",
        "        ans_start = torch.argmax(start).tolist()\n",
        "        ans_end = torch.argmax(end).tolist()\n",
        "        if (ans_start > sum(attention_mask[idx].tolist()) or ans_start > ans_end):\n",
        "          continue\n",
        "        if (ans_end < sum(attention_mask[idx].tolist())):\n",
        "          pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:ans_end]))\n",
        "        else:\n",
        "          pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:]))\n",
        "\n",
        "      # check if no answer\n",
        "      exact_match += max((compute_exact_match(pred, answer)) for answer in dev_df['all_answers'][idx])\n",
        "      f1_score += max((compute_f1(pred, answer)) for answer in dev_df['all_answers'][idx])\n",
        "\n",
        "  # em_scores = exact_match/total_dev\n",
        "  # f1_scores = f1_score/total_dev\n",
        "  # accuracy_dev = batch_acc_dev/total_dev\n",
        "  # train_loss = sum(batch_losses)/len(train_dataloader)\n",
        "  # epoch_loss.append(train_loss)\n",
        "  # epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  # print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB1TzI5D5kED"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7U4iNgwizca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "bbc010b6-a270-4389-a1be-9edae6d01bc3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7df275030de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for batch in validation_dataloader:\n",
        "\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    start_positions = batch['start_positions'].to(device)\n",
        "    end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "    start_logits, end_logits =  model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=False) \n",
        "\n",
        "    start_logits = start_logits.detach().cpu()\n",
        "    end_logits = end_logits.detach().cpu()\n",
        "\n",
        "    # correct predictions\n",
        "    for idx, (start, end) in enumerate(zip(start_logits, end_logits)):\n",
        "      ans_start = torch.argmax(start).tolist()\n",
        "      ans_end = torch.argmax(end).tolist()\n",
        "      if (ans_start > sum(attention_mask[idx].tolist()) or ans_start > ans_end):\n",
        "        continue\n",
        "      if (ans_end < sum(attention_mask[idx].tolist())):\n",
        "        pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:ans_end]))\n",
        "      else:\n",
        "        pred = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:]))\n",
        "\n",
        "    exact_match += max((compute_exact_match(pred, answer)) for answer in dev_df['all_answers'][idx])\n",
        "    f1_score += max((compute_f1(pred, answer)) for answer in dev_df['all_answers'][idx])\n",
        "\n",
        "print(\"f1_score : \", f1_score, \"exact match : \", exact_match)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC9lv2G45kEM"
      },
      "outputs": [],
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train']);\n",
        "\n",
        "plot_graph_loss(EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq4J8TA45kEM"
      },
      "outputs": [],
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['validation']);\n",
        "\n",
        "plot_graph_acc(EPOCHS)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcONvJ9HNAYt"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"trivia_qa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BpTpWKtNLe2"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"natural_questions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ag24W7NY2b"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"quac\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDv_LZk3NkV5"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"newsqa\", \"combined-csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "squad_(2)_(2)_(1) (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17078ff067d045f7ba5bcd362f3878df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8295ef7f4d1b435981d4b29653be5c6b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e46e67e389d74ef89a44d9e3c0f7a702",
              "IPY_MODEL_901b1411e59e4a08bf493514efe46fc6",
              "IPY_MODEL_1ea0b5651ab74fa58766b126146ef868"
            ]
          }
        },
        "8295ef7f4d1b435981d4b29653be5c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e46e67e389d74ef89a44d9e3c0f7a702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abdd4a1050414c5ebb03db240b7cbfd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_058b7460c5d04a20bd0c7baaf5f3406b"
          }
        },
        "901b1411e59e4a08bf493514efe46fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bdd4d30337f64abe92c3fed6ad46cfdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef33c446085148639e02955751e9409c"
          }
        },
        "1ea0b5651ab74fa58766b126146ef868": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb05010e58664763a2433b963f1e92d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  5.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56f172e75c5f404a91a0d27bf4e9314d"
          }
        },
        "abdd4a1050414c5ebb03db240b7cbfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "058b7460c5d04a20bd0c7baaf5f3406b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdd4d30337f64abe92c3fed6ad46cfdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef33c446085148639e02955751e9409c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb05010e58664763a2433b963f1e92d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56f172e75c5f404a91a0d27bf4e9314d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}