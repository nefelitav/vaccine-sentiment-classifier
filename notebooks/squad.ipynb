{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Question Answering with Bert\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook, I use a pre-trained Bert model to answer questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jl8wlD1VRC3F"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sB8j3615BTwM"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import re\n",
        "import csv\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from datasets import load_dataset\n",
        "import logging\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers.logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAyVZ0n9vIbG"
      },
      "source": [
        "## Use GPU for faster processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zeJXsqMvFAo",
        "outputId": "3d7b5423-ee50-4d0a-8f13-8f5dadbb6e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Available device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0pyqUGe6pQQ"
      },
      "source": [
        "## Load Bert tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8kDVDFUd2IGt"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
        "#model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Useful functions for training"
      ],
      "metadata": {
        "id": "odjlytbyhAUf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "raW-K-YBFcAi"
      },
      "outputs": [],
      "source": [
        "def normalize_text(s):\n",
        "\n",
        "    def remove_articles(text):\n",
        "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "        return re.sub(regex, \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "    \n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = normalize_text(prediction).split()\n",
        "    truth_tokens = normalize_text(truth).split()\n",
        "    \n",
        "    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return int(pred_tokens == truth_tokens)\n",
        "    \n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    \n",
        "    # if there are no common tokens then f1 = 0\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0\n",
        "    \n",
        "    prec = len(common_tokens) / len(pred_tokens)\n",
        "    rec = len(common_tokens) / len(truth_tokens)\n",
        "    \n",
        "    return 2 * (prec * rec) / (prec + rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SQuAD"
      ],
      "metadata": {
        "id": "GumLt6K0gqZQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "### Upload dataset - Create and Clean dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M28aYwiSWODa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "77d371f9692e4ca19acd233676b3434b",
            "789a7a37ea2f4c90827ee7f6449064a0",
            "b576233ad8fb4b4cb4ecf867a992303b",
            "7da438246db049c49edf41957fb651d1",
            "92fa989705ad4f298dd65917889e4e73",
            "6a84e6fa6a664fdebe0bd11f1e485cf7",
            "bf6dde209c0f4104a1ceec16a4d10eba",
            "054192f129bc417482c69218988ff2c5",
            "9e7629ed4d5b4378aa3ffdbacf89df9c",
            "710309dd741b497e86bc79b709b24c27",
            "e66b9cd6de254d1cbf0f45644ceb5c6e"
          ]
        },
        "outputId": "06d993eb-c4ca-460a-ea1d-55bdb328f784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77d371f9692e4ca19acd233676b3434b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_df, dev_df = load_dataset('squad_v2', split=['train', 'validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cUhbLBEpj-FC"
      },
      "outputs": [],
      "source": [
        "# convert to dataframes\n",
        "train_df = pd.DataFrame(train_df)\n",
        "dev_df = pd.DataFrame(dev_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PA5rkJ9_OV-Z"
      },
      "outputs": [],
      "source": [
        "# train_df = train_df.iloc[0:10,:]\n",
        "# dev_df = dev_df.iloc[0:10,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MLSekm-spl7O"
      },
      "outputs": [],
      "source": [
        "# remove empty instances / duplicates / extra columns\n",
        "train_df.dropna(subset = [\"question\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"question\"], inplace=True)\n",
        "\n",
        "train_df.drop(['id'], axis = 1, inplace = True) \n",
        "train_df.drop(['title'], axis = 1, inplace = True) \n",
        "dev_df.drop(['id'], axis = 1, inplace = True) \n",
        "dev_df.drop(['title'], axis = 1, inplace = True) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataframe(df):\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  answer_start = []\n",
        "  answer_end = []\n",
        "  all_answers = []\n",
        "\n",
        "  for index, row in df.iterrows():                          # for each instance\n",
        "    if (row['answers']['text']):                            # if there is an answer\n",
        "      for j, ans in enumerate(row['answers']['text']):        # for each answer\n",
        "        text_length = len(ans)\n",
        "        start_idx = row['answers']['answer_start'][j]\n",
        "        end_idx = start_idx + text_length\n",
        "        if (row['context'][start_idx:end_idx] == ans):        # found the start and end of the answer\n",
        "          answer_start.append(start_idx)\n",
        "          answer_end.append(end_idx)\n",
        "        else:                                               # it can be off by 1 or 2 characters\n",
        "          start = 0\n",
        "          end = 0\n",
        "          for i in [1, 2]:\n",
        "            if row['context'][start_idx-i:end_idx-i] == ans:\n",
        "                start = start_idx - i\n",
        "                end = end_idx - i\n",
        "          answer_start.append(start)\n",
        "          answer_end.append(end)\n",
        "        context.append(row['context'])\n",
        "        question.append(row['question'])\n",
        "        answer.append(ans)\n",
        "        all_answers.append(row['answers']['text'])          # save all plausible answers\n",
        "    else:                                                   # no answer -> set to None every column regarding the answers\n",
        "      context.append(row['context'])\n",
        "      question.append(row['question'])\n",
        "      answer.append(None)\n",
        "      all_answers.append(None)\n",
        "      answer_start.append(None)\n",
        "      answer_end.append(None)\n",
        "    \n",
        "\n",
        "  answer_dict = {'text': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n",
        "  return {'context': context, 'question': question, 'answer': answer_dict, 'all_answers': all_answers}\n",
        "\n",
        "train_df = get_dataframe(train_df)\n",
        "dev_df = get_dataframe(dev_df)"
      ],
      "metadata": {
        "id": "q85UK1MtBkKo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BmIuHi1lNRcj"
      },
      "outputs": [],
      "source": [
        "# get answers' token positions using answers' character positions\n",
        "def add_token_positions(encoding, answer, answer_start, answer_end):\n",
        "    start = []\n",
        "    end = []\n",
        "    for i in range(len(answer[\"text\"])):\n",
        "      if (answer['answer_start'][i] == None):\n",
        "        start.append(0)\n",
        "        end.append(0)\n",
        "        continue\n",
        "      start.append(encoding.char_to_token(i, answer['answer_start'][i]))\n",
        "      end.append(encoding.char_to_token(i, answer['answer_end'][i]))\n",
        "      if start[-1] is None:\n",
        "        start[-1] = tokenizer.model_max_length\n",
        "      if end[-1] is None:\n",
        "        end[-1] = encoding.char_to_token(i, answer['answer_end'][i] - 1)\n",
        "      if end[-1] is None:\n",
        "        end[-1] = tokenizer.model_max_length\n",
        "    return start, end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3cRBgVVRcvle"
      },
      "outputs": [],
      "source": [
        "# create dataset class to gather and organize all info\n",
        "class SquadDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, encodings):\n",
        "    self.encodings = encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    dict = {}\n",
        "    for key, val in self.encodings.items():\n",
        "      dict[key] = torch.tensor(val[idx])\n",
        "    return dict\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(train_df, dev_df, BATCH_SIZE):\n",
        "  # training data\n",
        "  encoding = tokenizer(train_df[\"context\"], train_df[\"question\"],\n",
        "                      truncation = True, \n",
        "                      padding = \"max_length\", max_length = 400,\n",
        "                      return_attention_mask = True)\n",
        "\n",
        "  # validation data\n",
        "  encoding_dev = tokenizer(dev_df[\"context\"], dev_df[\"question\"],\n",
        "                      truncation = True, \n",
        "                      padding = \"max_length\", max_length = 400,\n",
        "                      return_attention_mask = True)\n",
        "\n",
        "  encoding['start_positions'], encoding['end_positions'] = add_token_positions(encoding, train_df[\"answer\"], train_df[\"answer\"][\"answer_start\"], train_df[\"answer\"][\"answer_end\"])\n",
        "  encoding_dev['start_positions'], encoding_dev['end_positions']  = add_token_positions(encoding_dev,  dev_df[\"answer\"], dev_df[\"answer\"][\"answer_start\"], dev_df[\"answer\"][\"answer_end\"])\n",
        "\n",
        "  train_dataset = SquadDataset(encoding)\n",
        "  validation_dataset = SquadDataset(encoding_dev)\n",
        "\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "  return train_dataloader, validation_dataloader"
      ],
      "metadata": {
        "id": "sD02sWWX5VpJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "train_dataloader, validation_dataloader = get_dataloaders(train_df, dev_df, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "C5yCQe8k5N-9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OeqiS6QtA4b"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oDlxsbgwtAAN"
      },
      "outputs": [],
      "source": [
        "#Define Hyperparameters\n",
        "learning_rate = 1e-5\n",
        "\n",
        "#Initialize optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)#, weight_decay=0.001)\n",
        "\n",
        "clip = 2\n",
        "\n",
        "#model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training-Validation"
      ],
      "metadata": {
        "id": "kkLvcB7MhV4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0h9hsKHAb_kH"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "def train_model(train_dataloader):\n",
        "\n",
        "    batch_losses = []\n",
        "    loss = 0\n",
        "\n",
        "    # sets the mode to train\n",
        "    model.train()\n",
        "    for batch in train_dataloader:  # for every batch\n",
        "\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      token_type_ids = batch['token_type_ids'].to(device)\n",
        "      start_positions = batch['start_positions'].to(device)\n",
        "      end_positions = batch['end_positions'].to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      output = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, start_positions=start_positions, end_positions=end_positions)\n",
        "      \n",
        "      loss = output[0]\n",
        "      loss.backward()\n",
        "      batch_losses.append(loss)\n",
        "      #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      optimizer.step()\n",
        "\n",
        "    return sum(batch_losses)/len(train_dataloader)\n",
        "\n",
        "def validate_model(validation_dataloader):\n",
        "\n",
        "    exact_match = 0\n",
        "    f1_score = 0\n",
        "\n",
        "    # validation    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      # sets the mode to testing\n",
        "      model.eval()\n",
        "      for batch in validation_dataloader:\n",
        "\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        start_positions = batch['start_positions'].to(device)\n",
        "        end_positions = batch['end_positions'].to(device)\n",
        "\n",
        "        start_logits, end_logits =  model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=False) \n",
        "\n",
        "        start_logits = start_logits.detach().cpu()\n",
        "        end_logits = end_logits.detach().cpu()\n",
        "\n",
        "        # correct predictions\n",
        "        for idx, (start, end) in enumerate(zip(start_logits, end_logits)):\n",
        "          ans_start = torch.argmax(start).tolist()\n",
        "          ans_end = torch.argmax(end).tolist()\n",
        "          if (ans_start > sum(attention_mask[idx].tolist()) or ans_start > ans_end): # bigger than number of tokens or ending token\n",
        "            continue\n",
        "          if (ans_end < sum(attention_mask[idx].tolist())):\n",
        "            prediction = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:ans_end]))\n",
        "          else:\n",
        "            prediction = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[idx][ans_start:]))\n",
        "        \n",
        "          if (dev_df['all_answers'][idx] == None):\n",
        "            if (ans_start == 0 and ans_end == 0):\n",
        "              exact_match += 1\n",
        "              f1_score += 1\n",
        "              continue\n",
        "            else:\n",
        "              continue\n",
        "\n",
        "          exact_match += max((compute_exact_match(prediction, answer)) for answer in dev_df['all_answers'][idx])\n",
        "          f1_score += max((compute_f1(prediction, answer)) for answer in dev_df['all_answers'][idx])\n",
        "\n",
        "      return f1_score/len(validation_dataloader), exact_match/len(validation_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = train_model(train_dataloader)\n",
        "  f1_score, exact_match = validate_model(validation_dataloader)\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Validation F1 Score = {f1_score:.5f} | Validation Exact Match = {exact_match:.5f} \")"
      ],
      "metadata": {
        "id": "JVDFTcAjz2le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TriviaQA"
      ],
      "metadata": {
        "id": "mKWrnEwAhe_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcONvJ9HNAYt"
      },
      "outputs": [],
      "source": [
        "train_df, dev_df, test_df = load_dataset(\"trivia_qa\", 'rc' , split=['train[:10%]', 'validation[:10%]', 'test[:10%]'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to dataframes\n",
        "train_df = pd.DataFrame(train_df)\n",
        "dev_df = pd.DataFrame(dev_df)"
      ],
      "metadata": {
        "id": "TDYk27zFoVSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove empty instances / duplicates / extra columns\n",
        "train_df.dropna(subset = [\"question\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"question\"], inplace=True)\n",
        "\n",
        "train_df.drop(['question_source'], axis = 1, inplace = True) \n",
        "train_df.drop(['question_id'], axis = 1, inplace = True) \n",
        "train_df.drop(['entity_pages'], axis = 1, inplace = True) \n",
        "train_df.drop(['search_results'], axis = 1, inplace = True) \n",
        "\n",
        "train_df.drop(['question_source'], axis = 1, inplace = True) \n",
        "dev_df.drop(['question_id'], axis = 1, inplace = True) \n",
        "dev_df.drop(['entity_pages'], axis = 1, inplace = True) \n",
        "dev_df.drop(['search_results'], axis = 1, inplace = True) "
      ],
      "metadata": {
        "id": "ZP3YcIcVoiA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the information we need from data\n",
        "def get_data_triviaqa(df):\n",
        "\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  answer_start = []\n",
        "  answer_end = []\n",
        "  all_answers = []\n",
        "\n",
        "  for index, row in df.iterrows():                        # for each row - pair of question-answers\n",
        "      \n",
        "\n",
        "  answer_dict = {'text': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n",
        "  dict = {'question': question, 'answer': answer_dict, 'all_answers': all_answers}  \n",
        "  return dict\n",
        "\n",
        "train_df = get_data_triviaqa(train_df)\n",
        "dev_df = get_data_triviaqa(dev_df)"
      ],
      "metadata": {
        "id": "RAqMJ71trjCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['answer'][2]"
      ],
      "metadata": {
        "id": "PjfqRRj4qxHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quac"
      ],
      "metadata": {
        "id": "FMxYGEa2itj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ag24W7NY2b"
      },
      "outputs": [],
      "source": [
        "train_df, dev_df = dataset = load_dataset(\"quac\" , split=['train', 'validation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQvVRcHWZLIb"
      },
      "outputs": [],
      "source": [
        "# convert to dataframes\n",
        "train_df = pd.DataFrame(train_df)\n",
        "dev_df = pd.DataFrame(dev_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGFDJgkFGY0r"
      },
      "outputs": [],
      "source": [
        "# remove empty instances / duplicates / extra columns\n",
        "train_df.dropna(subset = [\"questions\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"questions\"], inplace=True)\n",
        "\n",
        "train_df.drop(['dialogue_id'], axis = 1, inplace = True) \n",
        "train_df.drop(['wikipedia_page_title'], axis = 1, inplace = True) \n",
        "train_df.drop(['background'], axis = 1, inplace = True) \n",
        "train_df.drop(['section_title'], axis = 1, inplace = True) \n",
        "train_df.drop(['turn_ids'], axis = 1, inplace = True) \n",
        "train_df.drop(['followups'], axis = 1, inplace = True) \n",
        "train_df.drop(['yesnos'], axis = 1, inplace = True) \n",
        "\n",
        "dev_df.drop(['dialogue_id'], axis = 1, inplace = True) \n",
        "dev_df.drop(['wikipedia_page_title'], axis = 1, inplace = True) \n",
        "dev_df.drop(['background'], axis = 1, inplace = True) \n",
        "dev_df.drop(['section_title'], axis = 1, inplace = True) \n",
        "dev_df.drop(['turn_ids'], axis = 1, inplace = True) \n",
        "dev_df.drop(['followups'], axis = 1, inplace = True) \n",
        "dev_df.drop(['yesnos'], axis = 1, inplace = True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIz2cC_8GY0r"
      },
      "outputs": [],
      "source": [
        "# get the information we need from data\n",
        "def get_data_quac(df):\n",
        "\n",
        "  context = []\n",
        "  question = []\n",
        "  answer = []\n",
        "  answer_start = []\n",
        "  answer_end = []\n",
        "  all_answers = []\n",
        "\n",
        "  for index, row in df.iterrows():                        # for each row - pair of question-answers\n",
        "      #all_answers.append(row['answers']['texts'])     \n",
        "      for i, answers in enumerate(zip(*row['orig_answers'].values())):\n",
        "        start_idx = answers[1]\n",
        "        end_idx = start_idx + len(answers[0])\n",
        "        if (row['context'][i][start_idx:end_idx] == row['orig_answers'][i]['texts']):\n",
        "          answer_start.append(start_idx)\n",
        "          answer_end.append(end_idx)\n",
        "        else:\n",
        "          start = 0\n",
        "          end = 0\n",
        "          for j in [1, 2]:                                  # maybe the answer is off by one or two chars\n",
        "            if row['context'][i][start_idx-j:end_idx-j] == row['orig_answers'][i]['texts']:\n",
        "                start = start_idx - j\n",
        "                end = end_idx - j\n",
        "          answer_start.append(start)\n",
        "          answer_end.append(end)\n",
        "        answer.extend(row['orig_answers']['texts'])\n",
        "      for q in row['questions']:\n",
        "        question.append(q)\n",
        "        context.append(row['context'])\n",
        "\n",
        "  answer_dict = {'text': answer, 'answer_start': answer_start, 'answer_end': answer_end}\n",
        "  dict = {'context': context, 'question': question, 'answer': answer_dict, 'all_answers': all_answers}  \n",
        "  return dict\n",
        "\n",
        "train_df = get_data_quac(train_df)\n",
        "dev_df = get_data_quac(dev_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NewsQA"
      ],
      "metadata": {
        "id": "EiUr83b3iwfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDv_LZk3NkV5"
      },
      "outputs": [],
      "source": [
        "train_df, dev_df = load_dataset(\"newsqa\", \"combined-csv\" , split=['train', 'validation'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "squad.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77d371f9692e4ca19acd233676b3434b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_789a7a37ea2f4c90827ee7f6449064a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b576233ad8fb4b4cb4ecf867a992303b",
              "IPY_MODEL_7da438246db049c49edf41957fb651d1",
              "IPY_MODEL_92fa989705ad4f298dd65917889e4e73"
            ]
          }
        },
        "789a7a37ea2f4c90827ee7f6449064a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b576233ad8fb4b4cb4ecf867a992303b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a84e6fa6a664fdebe0bd11f1e485cf7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf6dde209c0f4104a1ceec16a4d10eba"
          }
        },
        "7da438246db049c49edf41957fb651d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_054192f129bc417482c69218988ff2c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e7629ed4d5b4378aa3ffdbacf89df9c"
          }
        },
        "92fa989705ad4f298dd65917889e4e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_710309dd741b497e86bc79b709b24c27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00,  8.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e66b9cd6de254d1cbf0f45644ceb5c6e"
          }
        },
        "6a84e6fa6a664fdebe0bd11f1e485cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf6dde209c0f4104a1ceec16a4d10eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "054192f129bc417482c69218988ff2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e7629ed4d5b4378aa3ffdbacf89df9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "710309dd741b497e86bc79b709b24c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e66b9cd6de254d1cbf0f45644ceb5c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}