\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\Huge
\title{\Huge Artificial Intelligence II}
\usepackage{amsmath}
\author{\LARGE Nefeli Tavoulari}
\date{\LARGE Fall Semester 2021}

\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\begin{document}

\maketitle

\section{Vaccine Sentiment Classification}
In this notebook I trained two bidirectional stacked Recurrent Neural Networks with LSTM/GRU cells, which classify tweets as Neutral, Pro-vax or Anti-vax.

\subsection{Preprocessing}
First of all, I performed some preprocessing on the data, similar to the one I had done in the previous assignments. I removed all empty or duplicate tweets, as they offer no useful information to the model, I lowercased tweets, removed special characters, emojis, words written in a non-latin alphabet and urls, since I noticed that the results are better this way. Then, I used the GloVe pretrained Word Embeddings, to take advantage of the relationships between the words. More precisely, I used the ones that are extracted from tweets, since we are dealing with tweets too, I experimented with all the dimensions and I finally used the 100 dimensional embeddings. In this assignment, I took advantage of the Torchtext Machine Learning Framework, that is provided by PyTorch I built the vocabulary based on training and validation data and I
ended up with a matrix of $numberOfUniqueWords*EmbeddingsDimension$. Then, I split the data into batches of 64 instances, since that seems to be giving the best results.
\subsection{Models}
\begin{itemize}
\item The best bidirectional stacked LSTM model I created consists of an embedding layer, 3 recurrent layers, with hidden size of 64 and of course, a linear layer at the end. Also, I used Cross Entropy Loss to evaluate the model, Adam with learning rate of 1e-4 as optimizer and gradient clipping with max norm of 2, in order to avoid the problem of exploding gradients. Moreover, I used batches of 32 and 40 epochs to evaluate the model.

\item The best bidirectional stacked GRU model I created consists of an embedding layer, 3 recurrent layers, with hidden size of 128 and of course, a linear layer at the end. Also, I used Cross Entropy Loss to evaluate the model, Adam with learning rate of 1e-4 as optimizer and gradient clipping with max norm of 2, in order to avoid the problem of exploding gradients. Moreover, I used batches of 32 and 40 epochs to evaluate the model.
\end{itemize}
After preprocessing the data, using 2 LSTM/GRU layers, 64 hidden size, bidirectional RNNs,no gradient clipping,learning rate of 1e-4, batch size of 64 and vocabulary built on both training and validation data, the accuracy/precision/recall/F1 results I got, experimenting with different configurations, were the following on the validation data: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
200d  & 0.6038 & 0.6362\\
100d  & 0.6529 & \textbf{0.6538}\\
50d  & \textbf{0.6555} & 0.6437\\
25d  & 0.5626 & 0.6354\\
\end{Vmatrix}$ \\ \\ \\
So, using the 100d embeddings: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
without\ preprocessing  & 0.5836 & 0.5990\\
vocabulary\ without\ validation\ data  & 0.5985 & 0.6327\\
with\ preprocessing\ and\ validation\ data\ in\ vocab & \textbf{0.6529} & \textbf{0.6538} \\
\end{Vmatrix}$ \\ \\ \\
Then, with preprocessing of tweets and using training and validation data to build the vocabulary: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
batch\ size\ 64  & 0.6529 & 0.6538\\
batch\ size\ 32  & \textbf{0.6752} & \textbf{0.6779}\\
\end{Vmatrix}$ \\ \\ \\
Using batch size 32: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
2\ recurrent\ layers  & 0.6752 & 0.6779\\
3\ recurrent\ layers  & \textbf{0.6858} & \textbf{0.6871}\\
\end{Vmatrix}$ \\ \\ \\
Using 3 layers: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
128\ hidden\ size  & 0.6822 & \textbf{0.6954}\\
64\ hidden\ size  & \textbf{0.6858} & 0.6871\\
\end{Vmatrix}$ \\ \\ \\
Using 64 hidden size for recurrent layers in LSTM and 128 hidden size for recurrent layers in GRU: \\ \\
$\begin{Vmatrix}
1e-4\ learning\ rate & \textbf{0.6858} & \textbf{0.6954}\\
1e-3\ learning\ rate & 0.6779 & 0.7068(overfitting)\\
\end{Vmatrix}$ \\ \\ \\
Using learning rate of 1e-4: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
no\ clip  & 0.6858 & 0.6954\\
clip\ with\ max\ norm\ 1  & 0.6853 & 0.6792(overfitting)\\
clip\ with\ max\ norm\ 2  & \textbf{0.6967} & \textbf{0.7063}\\
clip\ with\ max\ norm\ 5  & 0.6801 & 0.6678(overfitting)\\
\end{Vmatrix}$\\ \\ \\
Using gradient clipping with a max norm of 2: \\ \\
$\begin{Vmatrix}
& LSTM & GRU \\
0.2\ dropout\ after\ all\ LSTM\ layers  & 0.6783 & 0.6831(overfitting)\\
0.5\ dropout\ after\ all\ LSTM\ layers & 0.6770 & 0.6577\\
except\ last\ one  & 0.6787 & 0.6945(overfitting)\\
0.2\ dropout\ only\ after\ last\ LSTM\ layer  & 0.6818 & 0.6901(overfitting)\\
0.2\ dropout\ after\ linear layer & 0.6546 & 0.6945661700262927\\
relu\ and\ dropout  & 0.6858 & 0.6879(overfitting)\\
without\ anything & \textbf{0.6967} & \textbf{0.7063}
\end{Vmatrix}$ \\ \\ \\
So, the model performs better without any activation function or dropout. \\
\subsection{Attention}
Using an attention layer, so that the model focuses on one part each time: \\ \\
$\begin{Vmatrix}
LSTM & GRU \\
0.7063(overfitting) & 0.6700(overfitting)\\
\end{Vmatrix}$ \\ \\ \\
Here, I have to remark that for every "overfitting" note, I mean that the model seemed to be overfitting, looking at the plots of Epochs Vs Accuracy or Epochs Vs Loss, as the validation loss was incrementing and the validation accuracy decrementing, while training. \\ \\
So, unfortunately, the attention layer did not improve my models' results, but it caused overfitting, as observed by the plots. \\ \\
To address this issue, I experimenting with Batch Normalization and Layer Normalization, but neither of these seemed to work.
\subsection{Evaluation - Comparison}
Using different metrics, precision, recall, f1 score, accuracy, confusion matrix, roc auc, I was able to determine the quality of my models. Therefore, the results are the following on the validation data: \\ \\
$
\begin{Vmatrix}
& Accuracy & Precision &  Recall & F1 \\
LSTM & 0.6967 & 0.6967 & 0.6967 & 0.6967\\
GRU & 0.7063 & 0.7063 & 0.7063 & 0.7063\\
\end{Vmatrix} 
$ \\ \\ \\ \\
$
\begin{Vmatrix}
& AUC\ macro\ OVO\ & AUC\ weighted\ OVO  &  AUC\ macro\ OVR & AUC\ weighted\ OVR  \\
LSTM & 0.825968 & 0.828989 & 0.832075 & 0.831839 \\
GRU & 0.813940 & 0.819427  & 0.821371  & 0.829215 \\
\end{Vmatrix} 
$ \\ \\ \\
All in all, I consider the LSTM model to be better, because the GRU is slightly overfitting and the ROC scores are not as good.\\ \\
Here we can also see the results for all classes for the LSTM model: \\ \\
\includegraphics[width=100mm]{images/recall}
\\ \\
From the confusion matrix, I understand that my LSTM model makes good enough predictions, since the diagonal has quite bigger numbers even for the anti-vaxers who are very few in the data, in comparison to the other classes. \\The confusion matrix ,using the aforementioned model :
\begin{center}
\includegraphics[width=100mm]{images/confusion.png}
\end{center}

The ROC Curve for all the classes:
\begin{center}
\includegraphics[width=100mm]{images/roc.png}
\end{center}
We observe that the anti-vax class is not that well predicted as the other two classes.
However, the curves in general show that the model distinguishes the classes, since they lean towards the top left corner (TPR).
\begin{center}
\includegraphics[width=80mm]{images/loss.png}
\end{center}
\begin{center}
\includegraphics[width=80mm]{images/accuracy}
\end{center}
We observe that after some point, the model does not learn that much, the loss increases and the accuracy descreases, on the validation set.
In general, however, the behavior of the curves is the expected one.That means that the accuracy increases and the loss decreases as the model learns.

Finally, I want to note that the results are sligthly worse than the ones obtained by the Logistic Regression model of the first assignment(7.3 accuracy), but better than the ones obtained by the feedforward network of the second assignment(6.5 accuracy). One reason behind this could be the fact the RNN models are too complex for such a task and of course the dataset is too small to get some good accuracy. However, the results are satisfactory, considering we are experimenting for the first time with all these difficult and interesting concepts.
\begin{thebibliography}{9}
\bibitem{}
\href{https://pytorch.org/docs/stable/nn.html#non-linear-activations-other}{PyTorch Documentation} 
\bibitem{}
\href{https://torchtext.readthedocs.io/en/latest/index.html}{Torchtext Documentation}
\bibitem{}
\href{https://medium.com/intel-student-ambassadors/implementing-attention-models-in-pytorch-f947034b3e66}{Attention}
\bibitem{}
\href{https://www.analyticsvidhya.com/blog/2021/08/all-you-need-to-know-about-skip-connections/}{Skip Connections}
\bibitem{}
\href{https://towardsdatascience.com/lstm-text-classification-using-pytorch-2c6c657f8fc0}{LSTM example}
\end{thebibliography}
\end{document}
