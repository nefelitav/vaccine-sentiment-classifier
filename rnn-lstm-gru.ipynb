{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feedforward.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Vaccine Sentiment Classification\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook I classify tweets as Neutral, Pro-vax or Anti-vax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8wlD1VRC3F",
        "outputId": "a970395a-2930-45e4-83cc-9c0e7fdbde52"
      },
      "source": [
        "!pip install -U torch==1.8.0 torchtext==0.9.0\n",
        "!pip install "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8j3615BTwM",
        "outputId": "bca0cb72-37dc-499d-f8ae-7583bb92e100"
      },
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "import random\n",
        "import os\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data   \n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, accuracy_score, mean_absolute_error\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Reproducibility Seed"
      ],
      "metadata": {
        "id": "H9MlTojEikPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed = 1234):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed()\n",
        "\n",
        "device = 'cpu'\n",
        "print('Working on:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cma41jCSiisj",
        "outputId": "c1448541-e466-48e9-c2d2-9174ebb838a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "## Upload dataset - Create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mBmlpIlBt84",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e5ed7247-4573-4515-9dd7-b13ab0c2071d"
      },
      "source": [
        "upload_train = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c522084-9933-442c-af51-c2bc498dc527\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c522084-9933-442c-af51-c2bc498dc527\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_train.csv to vs_train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzdiqaTBv_E",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "9bc56819-f8e6-4e92-a03a-92ce65779967"
      },
      "source": [
        "upload_dev = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35916516-8f92-429d-97ec-f7c889b2d580\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35916516-8f92-429d-97ec-f7c889b2d580\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_dev.csv to vs_dev (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrknN4jRbeN6"
      },
      "source": [
        "## Upload Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8v30jvy8JOx"
      },
      "source": [
        "def load_glove_model(File):\n",
        "    print(\"Loading Glove Model\")\n",
        "    glove_model = {}\n",
        "    with open(File,'r') as f:\n",
        "        for line in f:\n",
        "            split_line = line.split()\n",
        "            word = split_line[0]\n",
        "            embedding = np.array(split_line[1:], dtype=np.float64)\n",
        "            glove_model[word] = embedding\n",
        "    print(f\"{len(glove_model)} words loaded!\")\n",
        "    return glove_model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xukjiAFj86dI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff239b9f-c9dc-47bd-bce6-fffb881ec9a4"
      },
      "source": [
        "!wget https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!unzip glove.twitter.27B.zip\n",
        "# free some space\n",
        "!rm glove.twitter.27B.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-22 19:03:28--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2021-12-22 19:03:28--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  5.02MB/s    in 4m 45s  \n",
            "\n",
            "2021-12-22 19:08:14 (5.08 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "replace glove.twitter.27B.25d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.twitter.27B.25d.txt  y\n",
            "\n",
            "replace glove.twitter.27B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.twitter.27B.50d.txt  y\n",
            "y\n",
            "\n",
            "replace glove.twitter.27B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.twitter.27B.100d.txt  y\n",
            "y\n",
            "\n",
            "replace glove.twitter.27B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: glove.twitter.27B.200d.txt  y\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLj-OVw0mFuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20459665-fbff-42c1-fdb3-e7ddeec1448d"
      },
      "source": [
        "gloveModel = load_glove_model(\"glove.twitter.27B.25d.txt\")\n",
        "dim = 25\n",
        "#\n",
        "#gloveModel = load_glove_model(\"glove.twitter.27B.50d.txt\")\n",
        "#dim = 50\n",
        "#\n",
        "#gloveModel = load_glove_model(\"glove.twitter.27B.100d.txt\")\n",
        "#dim = 100\n",
        "#\n",
        "#gloveModel = load_glove_model(\"glove.twitter.27B.200d.txt\")\n",
        "#dim = 200\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Glove Model\n",
            "1193514 words loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crl8Sc9YByK9"
      },
      "source": [
        "train_df = pd.read_csv(io.BytesIO(upload_train['vs_train.csv']))\n",
        "dev_df = pd.read_csv(io.BytesIO(upload_dev['vs_dev.csv']))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKStHo66Bz8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ca450ac-09a9-495e-c66b-d769abb5cad3"
      },
      "source": [
        "print(train_df) # training data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Unnamed: 0                                              tweet  label\n",
            "0               0  Sip N Shop Come thru right now #Marjais #Popul...      0\n",
            "1               1  I don't know about you but My family and I wil...      1\n",
            "2               2  @MSignorile Immunizations should be mandatory....      2\n",
            "3               3  President Obama spoke in favor of vaccination ...      0\n",
            "4               4  \"@myfoxla: Arizona monitoring hundreds for mea...      0\n",
            "...           ...                                                ...    ...\n",
            "15971       15971  @Salon if u believe the anti-vax nutcases caus...      1\n",
            "15972       15972  How do you feel about parents who don't #vacci...      0\n",
            "15973       15973  70 Preschoolers Tested for Measles in Simi Val...      0\n",
            "15974       15974  Finance Minister: Budget offers room to procur...      0\n",
            "15975       15975  Are you up to date on vaccines? Take CDC’s vac...      2\n",
            "\n",
            "[15976 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W3hygNmB05X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74e3827-5243-4ae7-d2ea-abfe68b16734"
      },
      "source": [
        "print(dev_df) # validation data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0                                              tweet  label\n",
            "0              0  @user They had a massive surge in with covid d...      1\n",
            "1              1  Required vaccines for school: Parents and guar...      0\n",
            "2              2  “@KCStar: Two more Johnson County children hav...      0\n",
            "3              3  NV can do better. Which states are the best (a...      2\n",
            "4              4  Nothing like killing ourselves w/ our own fear...      2\n",
            "...          ...                                                ...    ...\n",
            "2277        2277  RT @abc7: Number of measles cases reported in ...      0\n",
            "2278        2278  Evidence points to the idea that \"measles affe...      0\n",
            "2279        2279  Where's @SavedYouAClick \"@voxdotcom: Why you s...      2\n",
            "2280        2280  Some of my favorite people have autism. If tha...      2\n",
            "2281        2281  Coronavirus: The married couple behind the suc...      0\n",
            "\n",
            "[2282 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztXIRmkHGXVN"
      },
      "source": [
        "## Remove empty / duplicate tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_A522pkGZLn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6cfc67-b8de-45a4-8b82-e253b8ebcb9c"
      },
      "source": [
        "train_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "train_df.drop_duplicates(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "dev_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "train_df.drop(['Unnamed: 0'], axis=1, inplace = True) \n",
        "dev_df.drop(['Unnamed: 0'], axis=1, inplace = True) \n",
        "\n",
        "print(train_df.shape)\n",
        "print(dev_df.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15881, 2)\n",
            "(2282, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK5Qud3-cAYm"
      },
      "source": [
        "## Clean text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gco1RADEpk1w"
      },
      "source": [
        "def clean_text(text):\n",
        "  text = text.lower()                                           # lowercase\n",
        "  text = text.strip()                                           # remove white spaces\n",
        "  #text = ' '.join(re.sub(\"(@[A-Za-z0-9]+)\",\" \",text).split())   # remove twitter user accounts\n",
        "  text = re.sub(r'http\\S+', ' ', text)                          # remove urls\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text)                     # remove special characters\n",
        "  # perform lemmatization\n",
        "  cleaned_text = \"\"\n",
        "  for word in text.split() :\n",
        "    if word in stop_words:                                      # remove stopwords\n",
        "      continue\n",
        "    temp = lemmatizer.lemmatize(word)                           # lemmatize\n",
        "    #temp = snowball.stem(word)\n",
        "    #temp = lancaster.stem(word)\n",
        "    #temp = porter.stem(word)\n",
        "    cleaned_text += (temp + \" \")\n",
        "  return cleaned_text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvL7F6BKcT5c"
      },
      "source": [
        "cleaned_text = []                                  # clean training data\n",
        "for line in train_df[\"tweet\"]:\n",
        "  cleaned_text.append(clean_text(line))\n",
        "cleaned_text_val = []                              # clean validation data\n",
        "for line in dev_df[\"tweet\"]:\n",
        "  cleaned_text_val.append(clean_text(line))\n",
        "\n",
        "train_df = train_df.assign(clean_tweet = lambda x: cleaned_text)\n",
        "dev_df = dev_df.assign(clean_tweet = lambda x: cleaned_text_val)\n",
        "\n",
        "train_df.drop(['tweet'], axis=1, inplace = True) \n",
        "dev_df.drop(['tweet'], axis=1, inplace = True) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4up9Sn_dYHIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85d15ff-4b15-4b78-d8e1-b7fbb01fbb48"
      },
      "source": [
        "total_df = train_df.append(dev_df)\n",
        "total_df.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18163, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs10h234cr4V"
      },
      "source": [
        "### Use Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQrnaHErAf9I"
      },
      "source": [
        "vocab = {}\n",
        "for row in range(0, total_df.shape[0]):\n",
        "  vocab[row] = []\n",
        "i = 0\n",
        "for tweet in total_df[\"clean_tweet\"]: # each tweet\n",
        "  count = np.zeros(dim)  \n",
        "  for word in tweet.split():\n",
        "    if (word in gloveModel):\n",
        "      count += gloveModel[word]\n",
        "  for num in count/dim:\n",
        "    vocab[i].append(num)\n",
        "  i += 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD9rqxzcFCZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "fed0ae85-e525-4dbc-d974-057d0d7b8e0d"
      },
      "source": [
        "df = pd.DataFrame.from_dict(vocab, orient='index')\n",
        "#df = df.transpose()\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3ac06f1-5fb8-422d-b786-88eaf6499da2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.074209</td>\n",
              "      <td>0.174633</td>\n",
              "      <td>-0.018545</td>\n",
              "      <td>-0.030889</td>\n",
              "      <td>-0.051354</td>\n",
              "      <td>-0.050267</td>\n",
              "      <td>0.174427</td>\n",
              "      <td>0.031691</td>\n",
              "      <td>-0.011138</td>\n",
              "      <td>0.126046</td>\n",
              "      <td>-0.059712</td>\n",
              "      <td>-0.051399</td>\n",
              "      <td>-0.903162</td>\n",
              "      <td>-0.034106</td>\n",
              "      <td>-0.020152</td>\n",
              "      <td>-0.055038</td>\n",
              "      <td>0.026370</td>\n",
              "      <td>-0.129461</td>\n",
              "      <td>-0.080249</td>\n",
              "      <td>-0.004640</td>\n",
              "      <td>-0.054612</td>\n",
              "      <td>-0.052254</td>\n",
              "      <td>0.154567</td>\n",
              "      <td>0.132431</td>\n",
              "      <td>0.081430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.096885</td>\n",
              "      <td>0.198095</td>\n",
              "      <td>-0.036882</td>\n",
              "      <td>-0.027684</td>\n",
              "      <td>-0.064159</td>\n",
              "      <td>-0.100399</td>\n",
              "      <td>0.301494</td>\n",
              "      <td>-0.063744</td>\n",
              "      <td>-0.024514</td>\n",
              "      <td>0.023850</td>\n",
              "      <td>-0.076308</td>\n",
              "      <td>0.067945</td>\n",
              "      <td>-0.922091</td>\n",
              "      <td>0.012661</td>\n",
              "      <td>0.092259</td>\n",
              "      <td>0.003399</td>\n",
              "      <td>0.080930</td>\n",
              "      <td>-0.173531</td>\n",
              "      <td>0.035397</td>\n",
              "      <td>-0.089007</td>\n",
              "      <td>-0.018312</td>\n",
              "      <td>0.031987</td>\n",
              "      <td>-0.018892</td>\n",
              "      <td>0.075888</td>\n",
              "      <td>-0.009154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.040021</td>\n",
              "      <td>0.258818</td>\n",
              "      <td>-0.079311</td>\n",
              "      <td>-0.117769</td>\n",
              "      <td>-0.042948</td>\n",
              "      <td>-0.029355</td>\n",
              "      <td>0.461787</td>\n",
              "      <td>-0.403149</td>\n",
              "      <td>-0.017695</td>\n",
              "      <td>0.054543</td>\n",
              "      <td>-0.156850</td>\n",
              "      <td>0.092332</td>\n",
              "      <td>-1.501643</td>\n",
              "      <td>0.117023</td>\n",
              "      <td>0.250349</td>\n",
              "      <td>0.064133</td>\n",
              "      <td>0.097205</td>\n",
              "      <td>-0.161577</td>\n",
              "      <td>0.073152</td>\n",
              "      <td>-0.167225</td>\n",
              "      <td>-0.092468</td>\n",
              "      <td>0.156980</td>\n",
              "      <td>0.077036</td>\n",
              "      <td>-0.134057</td>\n",
              "      <td>-0.034076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.035770</td>\n",
              "      <td>0.332920</td>\n",
              "      <td>-0.080705</td>\n",
              "      <td>-0.037391</td>\n",
              "      <td>0.115634</td>\n",
              "      <td>-0.350312</td>\n",
              "      <td>0.212475</td>\n",
              "      <td>-0.222832</td>\n",
              "      <td>0.052082</td>\n",
              "      <td>-0.137239</td>\n",
              "      <td>0.060121</td>\n",
              "      <td>0.017058</td>\n",
              "      <td>-1.428052</td>\n",
              "      <td>0.010468</td>\n",
              "      <td>0.194881</td>\n",
              "      <td>-0.033724</td>\n",
              "      <td>-0.066033</td>\n",
              "      <td>-0.011467</td>\n",
              "      <td>0.148273</td>\n",
              "      <td>-0.270828</td>\n",
              "      <td>0.099840</td>\n",
              "      <td>0.127823</td>\n",
              "      <td>-0.090725</td>\n",
              "      <td>-0.291199</td>\n",
              "      <td>-0.178715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.010700</td>\n",
              "      <td>0.106362</td>\n",
              "      <td>-0.045609</td>\n",
              "      <td>-0.027944</td>\n",
              "      <td>-0.061994</td>\n",
              "      <td>-0.040095</td>\n",
              "      <td>0.175118</td>\n",
              "      <td>-0.341968</td>\n",
              "      <td>-0.027564</td>\n",
              "      <td>0.030356</td>\n",
              "      <td>0.145610</td>\n",
              "      <td>0.041177</td>\n",
              "      <td>-0.824256</td>\n",
              "      <td>0.154942</td>\n",
              "      <td>0.065042</td>\n",
              "      <td>-0.105719</td>\n",
              "      <td>0.084132</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.198163</td>\n",
              "      <td>-0.051885</td>\n",
              "      <td>-0.170522</td>\n",
              "      <td>-0.036614</td>\n",
              "      <td>-0.022403</td>\n",
              "      <td>-0.270810</td>\n",
              "      <td>-0.051687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18158</th>\n",
              "      <td>0.068196</td>\n",
              "      <td>0.232128</td>\n",
              "      <td>0.084904</td>\n",
              "      <td>-0.170493</td>\n",
              "      <td>0.003719</td>\n",
              "      <td>-0.088877</td>\n",
              "      <td>0.527260</td>\n",
              "      <td>0.026907</td>\n",
              "      <td>-0.020015</td>\n",
              "      <td>0.118675</td>\n",
              "      <td>-0.070675</td>\n",
              "      <td>0.160058</td>\n",
              "      <td>-1.776028</td>\n",
              "      <td>0.137248</td>\n",
              "      <td>0.220457</td>\n",
              "      <td>-0.129746</td>\n",
              "      <td>0.188813</td>\n",
              "      <td>-0.176381</td>\n",
              "      <td>0.013349</td>\n",
              "      <td>-0.074251</td>\n",
              "      <td>-0.018184</td>\n",
              "      <td>0.080001</td>\n",
              "      <td>0.130804</td>\n",
              "      <td>-0.048743</td>\n",
              "      <td>-0.079874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18159</th>\n",
              "      <td>0.135183</td>\n",
              "      <td>0.103666</td>\n",
              "      <td>-0.183617</td>\n",
              "      <td>0.069301</td>\n",
              "      <td>0.194723</td>\n",
              "      <td>-0.035908</td>\n",
              "      <td>0.397737</td>\n",
              "      <td>-0.391050</td>\n",
              "      <td>0.025930</td>\n",
              "      <td>0.104589</td>\n",
              "      <td>0.088990</td>\n",
              "      <td>0.076809</td>\n",
              "      <td>-1.422444</td>\n",
              "      <td>0.272032</td>\n",
              "      <td>0.283920</td>\n",
              "      <td>0.007851</td>\n",
              "      <td>0.152214</td>\n",
              "      <td>0.103808</td>\n",
              "      <td>0.302962</td>\n",
              "      <td>-0.237584</td>\n",
              "      <td>-0.146742</td>\n",
              "      <td>0.087779</td>\n",
              "      <td>0.016166</td>\n",
              "      <td>-0.096209</td>\n",
              "      <td>-0.205875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18160</th>\n",
              "      <td>0.012991</td>\n",
              "      <td>0.094557</td>\n",
              "      <td>0.045770</td>\n",
              "      <td>0.002997</td>\n",
              "      <td>-0.000554</td>\n",
              "      <td>-0.057806</td>\n",
              "      <td>0.143313</td>\n",
              "      <td>-0.167676</td>\n",
              "      <td>-0.063106</td>\n",
              "      <td>-0.008966</td>\n",
              "      <td>-0.018790</td>\n",
              "      <td>0.015629</td>\n",
              "      <td>-0.523774</td>\n",
              "      <td>0.007312</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>-0.010261</td>\n",
              "      <td>0.048903</td>\n",
              "      <td>-0.101382</td>\n",
              "      <td>0.002362</td>\n",
              "      <td>-0.044212</td>\n",
              "      <td>-0.071073</td>\n",
              "      <td>0.078687</td>\n",
              "      <td>0.016030</td>\n",
              "      <td>-0.094016</td>\n",
              "      <td>-0.049905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18161</th>\n",
              "      <td>-0.094936</td>\n",
              "      <td>0.232104</td>\n",
              "      <td>-0.101476</td>\n",
              "      <td>0.067977</td>\n",
              "      <td>0.059048</td>\n",
              "      <td>-0.099540</td>\n",
              "      <td>0.410378</td>\n",
              "      <td>-0.217557</td>\n",
              "      <td>-0.181291</td>\n",
              "      <td>0.041748</td>\n",
              "      <td>-0.102457</td>\n",
              "      <td>0.161872</td>\n",
              "      <td>-1.260708</td>\n",
              "      <td>-0.074044</td>\n",
              "      <td>0.073398</td>\n",
              "      <td>0.053315</td>\n",
              "      <td>0.095231</td>\n",
              "      <td>-0.091243</td>\n",
              "      <td>0.197620</td>\n",
              "      <td>-0.116799</td>\n",
              "      <td>0.012127</td>\n",
              "      <td>0.090565</td>\n",
              "      <td>-0.012347</td>\n",
              "      <td>-0.159820</td>\n",
              "      <td>-0.066846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18162</th>\n",
              "      <td>-0.215949</td>\n",
              "      <td>0.276299</td>\n",
              "      <td>-0.063673</td>\n",
              "      <td>-0.081093</td>\n",
              "      <td>0.109579</td>\n",
              "      <td>-0.254964</td>\n",
              "      <td>0.326560</td>\n",
              "      <td>-0.403375</td>\n",
              "      <td>0.059703</td>\n",
              "      <td>-0.071088</td>\n",
              "      <td>0.176514</td>\n",
              "      <td>0.187138</td>\n",
              "      <td>-1.594836</td>\n",
              "      <td>0.096895</td>\n",
              "      <td>0.039772</td>\n",
              "      <td>0.060045</td>\n",
              "      <td>0.172573</td>\n",
              "      <td>-0.128602</td>\n",
              "      <td>0.081719</td>\n",
              "      <td>-0.102285</td>\n",
              "      <td>-0.036974</td>\n",
              "      <td>0.163457</td>\n",
              "      <td>-0.324558</td>\n",
              "      <td>-0.501477</td>\n",
              "      <td>-0.139040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18163 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3ac06f1-5fb8-422d-b786-88eaf6499da2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3ac06f1-5fb8-422d-b786-88eaf6499da2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3ac06f1-5fb8-422d-b786-88eaf6499da2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1         2   ...        22        23        24\n",
              "0     -0.074209  0.174633 -0.018545  ...  0.154567  0.132431  0.081430\n",
              "1     -0.096885  0.198095 -0.036882  ... -0.018892  0.075888 -0.009154\n",
              "2     -0.040021  0.258818 -0.079311  ...  0.077036 -0.134057 -0.034076\n",
              "3      0.035770  0.332920 -0.080705  ... -0.090725 -0.291199 -0.178715\n",
              "4      0.010700  0.106362 -0.045609  ... -0.022403 -0.270810 -0.051687\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "18158  0.068196  0.232128  0.084904  ...  0.130804 -0.048743 -0.079874\n",
              "18159  0.135183  0.103666 -0.183617  ...  0.016166 -0.096209 -0.205875\n",
              "18160  0.012991  0.094557  0.045770  ...  0.016030 -0.094016 -0.049905\n",
              "18161 -0.094936  0.232104 -0.101476  ... -0.012347 -0.159820 -0.066846\n",
              "18162 -0.215949  0.276299 -0.063673  ... -0.324558 -0.501477 -0.139040\n",
              "\n",
              "[18163 rows x 25 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKSYQD9YMcHd"
      },
      "source": [
        "train = df.iloc[:train_df.shape[0], :]\n",
        "dev = df.iloc[train_df.shape[0]:, :]\n",
        "\n",
        "x = torch.tensor(df.values, dtype=torch.float)\n",
        "y = torch.tensor(total_df['label'].values)\n",
        "\n",
        "x_train = torch.tensor(train.values, dtype=torch.float)\n",
        "y_train = torch.tensor(train_df['label'].values)\n",
        "\n",
        "x_dev = torch.tensor(dev.values, dtype=torch.float)\n",
        "y_dev = torch.tensor(dev_df['label'].values)\n",
        "\n",
        "# Initialize dataloaders\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "dev_dataset = TensorDataset(x_dev, y_dev)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBYKnos9o6qR"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "DVFJa3JHo_-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, num_features, num_hidden, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_features = num_features\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Network Parameters\n",
        "        # New cell content\n",
        "        self.Wxh = nn.Parameter(torch.randn((num_features, num_hidden)))\n",
        "        self.Whh = nn.Parameter(torch.randn((num_hidden, num_hidden)))\n",
        "        self.bh = nn.Parameter(torch.zeros((num_hidden)))\n",
        "        \n",
        "        # Input gate parameters\n",
        "        self.Wxh_i = nn.Parameter(torch.randn_like(self.Wxh))\n",
        "        self.Whh_i = nn.Parameter(torch.randn_like(self.Whh))\n",
        "        self.bh_i = nn.Parameter(torch.randn_like(self.bh))\n",
        "        \n",
        "        # Forget gate parameters\n",
        "        self.Wxh_f = nn.Parameter(torch.randn_like(self.Wxh))\n",
        "        self.Whh_f = nn.Parameter(torch.randn_like(self.Whh))\n",
        "        self.bh_f = nn.Parameter(torch.randn_like(self.bh))\n",
        "        \n",
        "        # Output gate parameters\n",
        "        self.Wxh_o = nn.Parameter(torch.randn_like(self.Wxh))\n",
        "        self.Whh_o = nn.Parameter(torch.randn_like(self.Whh))\n",
        "        self.bh_o = nn.Parameter(torch.randn_like(self.bh))\n",
        "        \n",
        "        # Hidden -> Output\n",
        "        self.Why = nn.Parameter(torch.randn((num_hidden, self.num_classes)))\n",
        "        self.by = nn.Parameter(torch.zeros((self.num_classes))) \n",
        "        \n",
        "        # Activations\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def init(self):\n",
        "        self.h = torch.zeros((self.num_hidden))  # Hidden state\n",
        "        self.c = torch.zeros((self.num_hidden))  # Cell state\n",
        "        \n",
        "    def forward(self, x):\n",
        "        potential_input = self.tanh((x @ self.Wxh) + (self.h @ self.Whh + self.bh))\n",
        "        \n",
        "        # Gate updates\n",
        "        input_gate = self.sigmoid((x @ self.Wxh_i) + (self.h @ self.Whh_i + self.bh_i))\n",
        "        forget_gate = self.sigmoid((x @ self.Wxh_f) + (self.h @ self.Whh_f + self.bh_f))\n",
        "        output_gate = self.sigmoid((x @ self.Wxh_o) + (self.h @ self.Whh_o + self.bh_o))\n",
        "        \n",
        "        # Update c and h\n",
        "        self.c = self.c * forget_gate + potential_input * input_gate\n",
        "        self.h = output_gate * self.tanh(self.c)\n",
        "        \n",
        "        y_output = self.h @ self.Why + self.by\n",
        "        \n",
        "        return y_output\n"
      ],
      "metadata": {
        "id": "QuJPKlyLnpk_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "5WQ2PjDMo2oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, num_features, num_hidden, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_features = num_features\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Network Parameters\n",
        "        # Potential Input\n",
        "        self.Wxh = nn.Parameter(torch.randn((num_features, num_hidden)))\n",
        "        self.Whh = nn.Parameter(torch.randn((num_hidden, num_hidden)))\n",
        "        self.bh = nn.Parameter(torch.zeros((num_hidden)))\n",
        "        \n",
        "        # Update gate parameters\n",
        "        self.Wxh_u = nn.Parameter(torch.randn_like(self.Wxh))\n",
        "        self.Whh_u = nn.Parameter(torch.randn_like(self.Whh))\n",
        "        self.bh_u = nn.Parameter(torch.randn_like(self.bh))\n",
        "        \n",
        "        # Reset gate parameters\n",
        "        self.Wxh_r = nn.Parameter(torch.randn_like(self.Wxh))\n",
        "        self.Whh_r = nn.Parameter(torch.randn_like(self.Whh))\n",
        "        self.bh_r = nn.Parameter(torch.randn_like(self.bh))\n",
        "        \n",
        "        # Hidden -> Output\n",
        "        self.Why = nn.Parameter(torch.randn((num_hidden, self.num_classes)))\n",
        "        self.by = nn.Parameter(torch.zeros((self.num_classes))) \n",
        "        \n",
        "        # Activations\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def init(self):\n",
        "        self.h = torch.zeros((self.num_hidden))  # Hidden state\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Gate updates\n",
        "        update_gate = self.sigmoid((x @ self.Wxh_u) + (self.h @ self.Whh_u + self.bh_u))\n",
        "        reset_gate = self.sigmoid((x @ self.Wxh_r) + (self.h @ self.Whh_r + self.bh_r))\n",
        "        \n",
        "        potential_input = self.tanh((x @ self.Wxh) + (reset_gate @ self.Whh + self.bh))\n",
        "        \n",
        "        self.h = self.h * (1-update_gate) + (potential_input * update_gate)\n",
        "        y_output = self.h @ self.Why + self.by\n",
        "        \n",
        "        return y_output"
      ],
      "metadata": {
        "id": "EoUWRlm7oBJD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Wrapper class that will hold the interface for LSTMs and GRUs\n",
        "    \"\"\"\n",
        "    cells = {\n",
        "        \"LSTM\"    : LSTMCell,\n",
        "        \"GRU\"     : GRUCell,\n",
        "    }\n",
        "    \n",
        "    def __init__(self, num_features, num_hidden=10, num_classes=3, cell_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.cell_type = cell_type\n",
        "        self.cell = RNN.cells[cell_type](num_features, num_hidden, num_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        for param in self.cell.parameters():\n",
        "            # Keep track of gradient for backprop\n",
        "            param.requires_grad_(True)\n",
        "            # If we deal with weights xavier initialization\n",
        "            if param.data.ndimension() >= 2:\n",
        "                nn.init.xavier_uniform_(param.data) #keep variance stability\n",
        "            # Else is a bias term so all zeros\n",
        "            else: \n",
        "                nn.init.zeros_(param.data)\n",
        "                \n",
        "    def forward(self, X):\n",
        "        # Setup outputs container (the output at each step)\n",
        "        outputs = torch.zeros(X.size(0),3)\n",
        "        # Iterate through sequence\n",
        "        self.cell.init()\n",
        "        for i, x in enumerate(X):\n",
        "          outputs[i] = self.cell(x)\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "VUYLtGtbnAhv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "Au5XC3zmo7nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 100\n",
        "LR = 0.01\n",
        "num_hidden = 10\n",
        "\n",
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "\n",
        "for CELL_TYPE in ['LSTM', 'GRU']:\n",
        "    print(f'Fitting {CELL_TYPE}...')\n",
        "\n",
        "    model = RNN(num_features=dim, num_hidden=num_hidden, num_classes=3, cell_type=CELL_TYPE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = []\n",
        "\n",
        "    # training\n",
        "    model.train()\n",
        "    for epoch in range(N_EPOCHS):\n",
        "\n",
        "      batch_losses = []\n",
        "      batch_acc = 0\n",
        "      total = 0\n",
        "      total_dev = 0\n",
        "      loss = 0\n",
        "      pred_proba = []\n",
        "\n",
        "      for x_batch, y_batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_batch)#.squeeze(1)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip params\n",
        "        for param in model.parameters():\n",
        "            if param.grad is None:\n",
        "                continue\n",
        "            grad_val = torch.clamp(param.grad, -5, 5)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Total number of labels\n",
        "        total += y_batch.size(0)\n",
        "        # Total correct predictions\n",
        "        _,pred_label = torch.max(y_pred, dim = 1)\n",
        "        batch_acc += (pred_label == y_batch).sum()\n",
        "        # Track loss\n",
        "        batch_losses.append(loss)\n",
        "\n",
        "      # validation    \n",
        "      with torch.no_grad():\n",
        "        \n",
        "        batch_losses_dev = []\n",
        "        batch_acc_dev = 0\n",
        "        model.eval()\n",
        "\n",
        "        for x_batch, y_batch in dev_dataloader:\n",
        "            y_dev_pred = model(x_batch).squeeze(1)\n",
        "            prob = F.softmax(y_dev_pred, dim=1)   # probability that an instance belogs to each class\n",
        "            for i in prob:\n",
        "              pred_proba.append(i.tolist())\n",
        "            loss_dev = criterion(y_dev_pred, y_batch)\n",
        "            batch_losses_dev.append(loss_dev)\n",
        "            # number of labels\n",
        "            total_dev += y_batch.size(0)\n",
        "            # correct predictions\n",
        "            _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "            batch_acc_dev += (pred_label == y_batch).sum()  \n",
        "\n",
        "      accuracy = batch_acc/total\n",
        "      accuracy_dev = batch_acc_dev/total_dev\n",
        "      train_loss = sum(batch_losses)/len(train_dataloader)\n",
        "      valid_loss = sum(batch_losses_dev)/len(dev_dataloader)\n",
        "      epoch_loss.append(train_loss)\n",
        "      epoch_loss_dev.append(valid_loss)\n",
        "      epoch_acc.append(accuracy)\n",
        "      epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "      print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f}\")"
      ],
      "metadata": {
        "id": "fwqaiUwWoP4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950ff719-6deb-4268-ff73-d5bd0bd2bce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting LSTM...\n",
            "Epoch   0: | Train Loss = 0.91320 | Train Accuracy = 0.55733 | Validation Loss = 0.85167 | Validation Accuracy = 0.59290\n",
            "Epoch   1: | Train Loss = 0.85131 | Train Accuracy = 0.60160 | Validation Loss = 0.82557 | Validation Accuracy = 0.61613\n",
            "Epoch   2: | Train Loss = 0.83470 | Train Accuracy = 0.61375 | Validation Loss = 0.81622 | Validation Accuracy = 0.61394\n",
            "Epoch   3: | Train Loss = 0.82650 | Train Accuracy = 0.61564 | Validation Loss = 0.82249 | Validation Accuracy = 0.60868\n",
            "Epoch   4: | Train Loss = 0.82152 | Train Accuracy = 0.61621 | Validation Loss = 0.80621 | Validation Accuracy = 0.61394\n",
            "Epoch   5: | Train Loss = 0.81439 | Train Accuracy = 0.62005 | Validation Loss = 0.81941 | Validation Accuracy = 0.61087\n",
            "Epoch   6: | Train Loss = 0.81190 | Train Accuracy = 0.62005 | Validation Loss = 0.80879 | Validation Accuracy = 0.61744\n",
            "Epoch   7: | Train Loss = 0.80873 | Train Accuracy = 0.62282 | Validation Loss = 0.79565 | Validation Accuracy = 0.61963\n",
            "Epoch   8: | Train Loss = 0.80543 | Train Accuracy = 0.62509 | Validation Loss = 0.80039 | Validation Accuracy = 0.60955\n",
            "Epoch   9: | Train Loss = 0.80012 | Train Accuracy = 0.62389 | Validation Loss = 0.79253 | Validation Accuracy = 0.62182\n",
            "Epoch  10: | Train Loss = 0.79790 | Train Accuracy = 0.62376 | Validation Loss = 0.78865 | Validation Accuracy = 0.62095\n",
            "Epoch  11: | Train Loss = 0.79444 | Train Accuracy = 0.62823 | Validation Loss = 0.79151 | Validation Accuracy = 0.62095\n",
            "Epoch  12: | Train Loss = 0.79105 | Train Accuracy = 0.62868 | Validation Loss = 0.78280 | Validation Accuracy = 0.63015\n",
            "Epoch  13: | Train Loss = 0.78914 | Train Accuracy = 0.63365 | Validation Loss = 0.78777 | Validation Accuracy = 0.62533\n",
            "Epoch  14: | Train Loss = 0.78547 | Train Accuracy = 0.63504 | Validation Loss = 0.78790 | Validation Accuracy = 0.62489\n",
            "Epoch  15: | Train Loss = 0.78784 | Train Accuracy = 0.63510 | Validation Loss = 0.77992 | Validation Accuracy = 0.62314\n",
            "Epoch  16: | Train Loss = 0.78344 | Train Accuracy = 0.63617 | Validation Loss = 0.78043 | Validation Accuracy = 0.62883\n",
            "Epoch  17: | Train Loss = 0.78205 | Train Accuracy = 0.63629 | Validation Loss = 0.78634 | Validation Accuracy = 0.62533\n",
            "Epoch  18: | Train Loss = 0.78182 | Train Accuracy = 0.63932 | Validation Loss = 0.78646 | Validation Accuracy = 0.62752\n",
            "Epoch  19: | Train Loss = 0.77956 | Train Accuracy = 0.64140 | Validation Loss = 0.78188 | Validation Accuracy = 0.62533\n",
            "Epoch  20: | Train Loss = 0.77748 | Train Accuracy = 0.63850 | Validation Loss = 0.77331 | Validation Accuracy = 0.63497\n",
            "Epoch  21: | Train Loss = 0.77632 | Train Accuracy = 0.63995 | Validation Loss = 0.77680 | Validation Accuracy = 0.62883\n",
            "Epoch  22: | Train Loss = 0.77368 | Train Accuracy = 0.64404 | Validation Loss = 0.77587 | Validation Accuracy = 0.63453\n",
            "Epoch  23: | Train Loss = 0.77481 | Train Accuracy = 0.64152 | Validation Loss = 0.77320 | Validation Accuracy = 0.63848\n",
            "Epoch  24: | Train Loss = 0.77166 | Train Accuracy = 0.64568 | Validation Loss = 0.76921 | Validation Accuracy = 0.63365\n",
            "Epoch  25: | Train Loss = 0.77022 | Train Accuracy = 0.64398 | Validation Loss = 0.77453 | Validation Accuracy = 0.63541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Complexity"
      ],
      "metadata": {
        "id": "2uSbHS9zoqd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features, num_hidden, num_classes = 300, 500, 1\n",
        "print('Number of Params:..')\n",
        "for cell_type in ['LSTM', 'GRU']:\n",
        "    model = RNN(num_features=dim, num_hidden=num_hidden, cell_type=cell_type)\n",
        "    model_param_count = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            c = 1\n",
        "            for val in param.shape:\n",
        "                c *= val\n",
        "        model_param_count += c\n",
        "    print(f'{cell_type} : {model_param_count}')"
      ],
      "metadata": {
        "id": "z8Z0neX6oeM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHPPRYbdkTLJ"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "true = y_dev\n",
        "pred = model(x_dev).squeeze(1)\n",
        "after_train = criterion(pred, true) \n",
        "print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "id": "_VhYsUjBKHGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,pred_label = torch.max(pred, dim = 1)"
      ],
      "metadata": {
        "id": "ax-feOgBT2GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyaNtxfgn2fj"
      },
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "df = pd.DataFrame({'true':true.numpy()})\n",
        "df2 = pd.DataFrame({'pred':pred_label.numpy()})\n",
        "cm = confusion_matrix(true.numpy(), pred_label.numpy())\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR4Ze3Mn9lj"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Test Data :\")\n",
        "print(precision_recall_fscore_support(true.numpy(), pred_label.numpy(), average='micro'))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Tp1qZzn63i"
      },
      "source": [
        "print(classification_report(true.numpy(), pred_label.numpy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = F.softmax(pred, dim=1)\n",
        "pred_proba = []\n",
        "for i in prob:\n",
        "  pred_proba.append(i.tolist())"
      ],
      "metadata": {
        "id": "D5OWhpS9fOpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWCY94YTNCtF"
      },
      "source": [
        "macro_roc_auc_ovo = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
        "weighted_roc_auc_ovo = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovo\", average=\"weighted\")\n",
        "macro_roc_auc_ovr = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
        "weighted_roc_auc_ovr = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
        "print(\n",
        "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
        ")\n",
        "print()\n",
        "print(\n",
        "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JucQf53RkPau"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdlP0xdcU_p_"
      },
      "source": [
        "# probabilities\n",
        "df_prob = pd.DataFrame(pred_proba)\n",
        "df_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHGuBmfJqWBm"
      },
      "source": [
        "# roc curve for classes\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh ={}\n",
        "\n",
        "n_class = 3\n",
        "\n",
        "for i in range(n_class):    \n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(true, df_prob[i], pos_label=i)\n",
        "    \n",
        "# plotting    \n",
        "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
        "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
        "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
        "plt.title('Multiclass ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Multiclass ROC',dpi=300);  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foSvkW0ytpxF"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_loss(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cJojWzkNQs"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_acc(100)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GZAQd93xYXE"
      },
      "source": [
        "## Second Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmu-PutrxYXG"
      },
      "source": [
        "class Net2(nn.Module):\n",
        "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "        super(Net2, self).__init__()\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(H1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.linear3 = nn.Linear(H2, H3)\n",
        "        self.linear4 = nn.Linear(H3, D_out)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.batchnorm1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.logsoftmax(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsnnrIHHxYXG"
      },
      "source": [
        "#Define layer sizes\n",
        "D_in = x.shape[1]\n",
        "H1 = 128\n",
        "H2 = 64\n",
        "H3 = 32\n",
        "D_out = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer, loss function\n",
        "model = Net2(D_in, H1, H2, H3, D_out)\n",
        "\n",
        "loss_func = nn.NLLLoss()                    # with softmax in output of model\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.01)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQgFSLqbxYXH"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TQMjNcxYXH"
      },
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for x_batch, y_batch in train_dataloader:  # for every batch\n",
        "    y_pred = model(x_batch).squeeze(1)\n",
        "    loss = loss_func(y_pred, y_batch)\n",
        "    batch_losses.append(loss)\n",
        "    #Delete previously stored gradients\n",
        "    optimizer.zero_grad()\n",
        "    #Perform backpropagation starting from the loss calculated in this epoch\n",
        "    loss.backward()\n",
        "    #Update model's weights based on the gradients calculated during backprop\n",
        "    optimizer.step()\n",
        "\n",
        "    # Total number of labels\n",
        "    total += y_batch.size(0)\n",
        "    # Total correct predictions\n",
        "    _,pred_label = torch.max(y_pred, dim = 1)\n",
        "    batch_acc += (pred_label == y_batch).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "\n",
        "    for x_batch, y_batch in dev_dataloader:\n",
        "        y_dev_pred = model(x_batch).squeeze(1)\n",
        "        loss_dev = loss_func(y_dev_pred, y_batch)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += y_batch.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        batch_acc_dev += (pred_label == y_batch).sum()\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_dataloader)\n",
        "  valid_loss = sum(batch_losses_dev)/len(dev_dataloader)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkg036AAxYXI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "true = y_dev\n",
        "pred = model(x_dev).squeeze(1)\n",
        "after_train = criterion(pred, true) \n",
        "print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "id": "fPROsyHhhroX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,pred_label = torch.max(pred, dim = 1)"
      ],
      "metadata": {
        "id": "KesKVNODhrog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPE7KRl7xYXI"
      },
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "df = pd.DataFrame({'true':true})\n",
        "df2 = pd.DataFrame({'pred':pred_label})\n",
        "cm = confusion_matrix(true, pred_label)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1AlvPI2xYXI"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(true, pred_label, average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZyYICtxYXJ"
      },
      "source": [
        "print(classification_report(true, pred_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SL-_dIexYXJ"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAvYEyVoxYXK"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "plot_graph_loss(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmfTebrxYXK"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "plot_graph_acc(100)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}