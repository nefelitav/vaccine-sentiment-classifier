{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vaccine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Vaccine Sentiment Classification\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook I classify tweets as Neutral, Pro-vax or Anti-vax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8wlD1VRC3F",
        "outputId": "cfd749b8-133e-4e8c-b6af-0d412f4d9cd2"
      },
      "source": [
        "!pip install -U torch==1.8.0 torchtext==0.9.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torchtext==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8j3615BTwM",
        "outputId": "5839e1a6-9ab5-413a-8459-134c0341cd02"
      },
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import re\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data   \n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, accuracy_score, mean_absolute_error\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "## Upload dataset - Create and Clean dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mBmlpIlBt84",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "457174c9-3fd1-4e96-e797-52269026e7e8"
      },
      "source": [
        "upload_train = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da1ec122-972e-4c48-8d21-97f711ee16a2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da1ec122-972e-4c48-8d21-97f711ee16a2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_train.csv to vs_train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzdiqaTBv_E",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "91a35b57-0a61-4f8c-f55e-3f81bc44df03"
      },
      "source": [
        "upload_dev = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fdf828b-1ee6-471d-8877-794139c6b31e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fdf828b-1ee6-471d-8877-794139c6b31e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_dev.csv to vs_dev (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crl8Sc9YByK9"
      },
      "source": [
        "train_df = pd.read_csv(io.BytesIO(upload_train['vs_train.csv']))\n",
        "dev_df = pd.read_csv(io.BytesIO(upload_dev['vs_dev.csv']))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "train_df.drop_duplicates(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "dev_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "train_df.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
        "dev_df.drop(['Unnamed: 0'], axis = 1, inplace = True) "
      ],
      "metadata": {
        "id": "MLSekm-spl7O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"tweet\"] = train_df[\"tweet\"].apply(lambda line: re.sub('[^A-Za-z0-9]+', ' ', re.sub(r'http\\S+', ' ',line.lower().strip())))\n",
        "dev_df[\"tweet\"] = dev_df[\"tweet\"].apply(lambda line: re.sub('[^A-Za-z0-9]+', ' ', re.sub(r'http\\S+', ' ',line.lower().strip())))"
      ],
      "metadata": {
        "id": "5I70w9IaQ5ym"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "dev_df.dropna(subset = [\"tweet\"], inplace=True)"
      ],
      "metadata": {
        "id": "rPpv7zCNtia4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKStHo66Bz8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842f6445-b8b9-46d8-b42e-c4a2242fb44e"
      },
      "source": [
        "print(train_df) # training data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet  label\n",
            "0      sip n shop come thru right now marjais popular...      0\n",
            "1      i don t know about you but my family and i wil...      1\n",
            "2       msignorile immunizations should be mandatory ...      2\n",
            "3      president obama spoke in favor of vaccination ...      0\n",
            "4       myfoxla arizona monitoring hundreds for measl...      0\n",
            "...                                                  ...    ...\n",
            "15971   salon if u believe the anti vax nutcases caus...      1\n",
            "15972  how do you feel about parents who don t vaccin...      0\n",
            "15973  70 preschoolers tested for measles in simi val...      0\n",
            "15974  finance minister budget offers room to procure...      0\n",
            "15975  are you up to date on vaccines take cdc s vacc...      2\n",
            "\n",
            "[15881 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W3hygNmB05X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df54760-cf58-4628-feb7-119b10194081"
      },
      "source": [
        "print(dev_df) # validation data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  tweet  label\n",
            "0      user they had a massive surge in with covid d...      1\n",
            "1     required vaccines for school parents and guard...      0\n",
            "2      kcstar two more johnson county children have ...      0\n",
            "3     nv can do better which states are the best and...      2\n",
            "4     nothing like killing ourselves w our own fear ...      2\n",
            "...                                                 ...    ...\n",
            "2277  rt abc7 number of measles cases reported in ca...      0\n",
            "2278  evidence points to the idea that measles affec...      0\n",
            "2279  where s savedyouaclick voxdotcom why you shoul...      2\n",
            "2280  some of my favorite people have autism if that...      2\n",
            "2281  coronavirus the married couple behind the succ...      0\n",
            "\n",
            "[2282 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrknN4jRbeN6"
      },
      "source": [
        "## Use Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(sequential=True, tokenize=\"spacy\", batch_first=True, include_lengths=True)\n",
        "LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)"
      ],
      "metadata": {
        "id": "kzTe1JsAWaZn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "dev_df.to_csv(\"valid.csv\", index=False)\n",
        "\n",
        "train_data, valid_data = data.TabularDataset.splits(\n",
        "    path=\"\", train=\"train.csv\", \n",
        "    validation=\"valid.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('tweet', TEXT), ('label', LABEL)]\n",
        ")\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')"
      ],
      "metadata": {
        "id": "maMN_J5LoYVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0379482d-a259-47f9-bdd4-dbeba830218f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 15881\n",
            "Number of validation examples: 2282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, vectors='glove.twitter.27B.25d', max_size=20000, min_freq=5)\n",
        "\n",
        "# get the vocab instance\n",
        "vocab = TEXT.vocab\n",
        "vocab.vectors"
      ],
      "metadata": {
        "id": "XgpUUassov5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cd377a-74cc-48c2-a106-ac4bb2862101"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0102,  0.0202,  0.2147,  ...,  0.1878, -0.8425, -0.3121],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.2294,  0.5248, -0.5126,  ..., -0.9748, -0.4564, -0.6522],\n",
              "        [-0.2263, -1.0418, -1.3316,  ...,  0.7902,  0.4736, -0.8039]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.freqs.most_common(10) # seems right"
      ],
      "metadata": {
        "id": "Q3JSXRCyoRF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dca9ee8-e815-4923-d762-7ec38ccbe0eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 8689),\n",
              " ('to', 6872),\n",
              " (' ', 5316),\n",
              " ('vaccine', 5106),\n",
              " ('a', 5053),\n",
              " ('measles', 4455),\n",
              " ('of', 4324),\n",
              " ('and', 4014),\n",
              " ('i', 3952),\n",
              " ('in', 3809)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.build_vocab(train_data)\n",
        "vocab_label = LABEL.vocab\n",
        "print(\"Size of LABEL vocabulary:\",len(vocab_label))\n",
        "vocab_label.freqs"
      ],
      "metadata": {
        "id": "VKw9ZjuRt80S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618cbb9f-5d8d-4230-e747-e076189e51f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of LABEL vocabulary: 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 7385, '1': 2070, '2': 6426})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "id": "WxUsiH2NuK46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4651dd-b927-4810-daed-688dfb319e25"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 4447\n",
            "Unique tokens in LABEL vocabulary: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Batch Iterator"
      ],
      "metadata": {
        "id": "1INLU0MPuOxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), sort_key=lambda x: len(x.tweet),\n",
        "    batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "LABEL.vocab.freqs"
      ],
      "metadata": {
        "id": "yPMosIgtZdXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e20d282-e0d9-46ba-cdcd-8fa1f058fb83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 7385, '1': 2070, '2': 6426})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "pretrained_embeddings.shape"
      ],
      "metadata": {
        "id": "KVUxUElhvbJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b85948f-a844-4562-a220-37edac439763"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4447, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK6vlfJgonll",
        "outputId": "6cb9699c-92b5-4e97-acf5-71d2fa0d5a79"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0102,  0.0202,  0.2147,  ...,  0.1878, -0.8425, -0.3121],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.2294,  0.5248, -0.5126,  ..., -0.9748, -0.4564, -0.6522],\n",
              "        [-0.2263, -1.0418, -1.3316,  ...,  0.7902,  0.4736, -0.8039]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBYKnos9o6qR"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, embedding_size, output_size, weights, bidirectional):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        #self.embedding.weight = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
        "                           hidden_size=self.hidden_size,\n",
        "                           dropout=0.2,\n",
        "                           num_layers=self.num_layers, \n",
        "                           bidirectional=self.bidirectional,\n",
        "                           batch_first=True\n",
        "                           )\n",
        "        \n",
        "        if self.bidirectional: \n",
        "          self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(hidden_size, self.output_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        out = x\n",
        "        if self.bidirectional:\n",
        "            h = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "            c = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        else:\n",
        "            h = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "            c = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        #x = pack_padded_sequence(x, text_len, batch_first=True, enforce_sorted=False)\n",
        "        \n",
        "        out, (ht, ct) = self.lstm(x, (h, c))\n",
        "         \n",
        "        #out, _ = pad_packed_sequence(out, batch_first=True)\n",
        "        #x, _ = pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "\n",
        "        if self.bidirectional: \n",
        "          out = out.contiguous().view(-1, self.hidden_size*2)\n",
        "        else:\n",
        "          out = out.contiguous().view(-1, self.hidden_size)\n",
        "          \n",
        "        #out = self.dropout(out)\n",
        "\n",
        "        out = self.fc(out)  \n",
        "        #print(out)\n",
        "\n",
        "        #Keep only the hidden representation of the last item of the sequence as the representative of the sample.\n",
        "        out = out.view(x.size(0), -1, self.output_size)\n",
        "\n",
        "        out = out[:, -1, :]\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "mIBXht8xCzSr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bwsrdCGKb_j5"
      },
      "outputs": [],
      "source": [
        "#Define layer sizes\n",
        "vocab_size = pretrained_embeddings.shape[0]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "embedding_size = pretrained_embeddings.shape[1]\n",
        "output_size = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer\n",
        "model = LSTM(vocab_size, hidden_size, num_layers, embedding_size, output_size, pretrained_embeddings, False)\n",
        "#model.embedding.weight.data = pretrained_embeddings\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.01)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "E9gQg2lXb_kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbea7ea-595c-49cc-9a4f-88c1b994189c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(4447, 25)\n",
              "  (lstm): LSTM(25, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0h9hsKHAb_kH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d510b64-11c5-4277-d854-beb3a7c81730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: | Train Loss = 0.96391 | Train Accuracy = 0.48564 | Validation Loss = 0.99894 | Validation Accuracy = 0.49241 \n",
            "Epoch   1: | Train Loss = 0.90713 | Train Accuracy = 0.56477 | Validation Loss = 0.94196 | Validation Accuracy = 0.49643 \n",
            "Epoch   2: | Train Loss = 0.86516 | Train Accuracy = 0.60307 | Validation Loss = 0.93990 | Validation Accuracy = 0.53482 \n",
            "Epoch   3: | Train Loss = 0.84535 | Train Accuracy = 0.61297 | Validation Loss = 0.93893 | Validation Accuracy = 0.54732 \n",
            "Epoch   4: | Train Loss = 0.83408 | Train Accuracy = 0.62027 | Validation Loss = 0.95109 | Validation Accuracy = 0.56652 \n"
          ]
        }
      ],
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "#clip = 5\n",
        "\n",
        "for epoch in range(5):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  pred_proba = []\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for (tweet, label) in train_iterator:  # for every batch\n",
        "    if tweet[0].shape[0] == BATCH_SIZE:\n",
        "      y_pred = model(tweet[0])\n",
        "      #print(y_pred.shape)\n",
        "      #print(y_pred)\n",
        "      loss = criterion(y_pred, label)\n",
        "      batch_losses.append(loss)\n",
        "      #Delete previously stored gradients\n",
        "      optimizer.zero_grad()\n",
        "      #Perform backpropagation starting from the loss calculated in this epoch\n",
        "      loss.backward()\n",
        "      #nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #Update model's weights based on the gradients calculated during backprop\n",
        "      optimizer.step()\n",
        "\n",
        "      # Total number of labels\n",
        "      total += label.size(0)\n",
        "      # Total correct predictions\n",
        "      _,pred_label = torch.max(y_pred, dim = 1)\n",
        "      batch_acc += (pred_label == label).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "    for (tweet, label) in valid_iterator:\n",
        "      if tweet[0].shape[0] == BATCH_SIZE:\n",
        "        y_dev_pred = model(tweet[0])\n",
        "        prob = F.softmax(y_dev_pred, dim=1)   # probability that an instance belogs to each class\n",
        "        #print(prob.shape)\n",
        "        for i in prob:\n",
        "          pred_proba.append(i.tolist())\n",
        "        loss_dev = criterion(y_dev_pred, label)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += label.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        #print(y_dev_pred, pred_label)\n",
        "        batch_acc_dev += (pred_label == label).sum()\n",
        "\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_iterator)\n",
        "  valid_loss = sum(batch_losses_dev)/len(valid_iterator)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB1TzI5D5kED"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid = pd.read_csv(\"valid.csv\")"
      ],
      "metadata": {
        "id": "5iTCrzm5zlGT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    tokenized = [tok for tok in sentence.split()]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed)\n",
        "    #print(tensor.shape)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    #print(tensor)\n",
        "    #print(tensor.shape)\n",
        "    prediction = model(tensor)\n",
        "    #print(prediction.shape)\n",
        "\n",
        "    #print(F.softmax(prediction, dim=-1))\n",
        "    preds, ind = torch.max(F.softmax(prediction, dim=-1), 1)\n",
        "    #print(preds, ind)\n",
        "    return preds, ind, F.softmax(prediction, dim=-1)\n"
      ],
      "metadata": {
        "id": "wHEz6tcuzEz4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [predict(k)[1].numpy() for k in valid.tweet]\n",
        "pred_proba = [predict(k)[2] for k in valid.tweet]\n",
        "\n",
        "print(classification_report(valid.label, pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U4iNgwizca5",
        "outputId": "706bdae3-8c0f-4aff-afef-f62ecb4d9d95"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.37      0.52      1065\n",
            "           1       0.60      0.01      0.02       296\n",
            "           2       0.47      0.94      0.63       921\n",
            "\n",
            "    accuracy                           0.55      2282\n",
            "   macro avg       0.65      0.44      0.39      2282\n",
            "weighted avg       0.67      0.55      0.50      2282\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "_iACQLKz_Xsw",
        "outputId": "4bf60fd8-abd8-44a5-e116-2fbaa84ea29b"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, accuracy_score, mean_absolute_error\n",
        "\n",
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "\n",
        "cm = confusion_matrix(valid.label, pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca339543-f8b8-431b-df0a-37301259e8db",
        "id": "DfX_7laH5kEL"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(valid.label, pred, average='micro'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision-Recall-F1 - Training Data :\n",
            "(0.5530236634531113, 0.5530236634531113, 0.5530236634531113, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proba_list = []\n",
        "for i in pred_proba:\n",
        "  proba_list.append(i.squeeze(0).tolist())\n",
        "#proba_list"
      ],
      "metadata": {
        "id": "W_6R-8SCMlNG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5134ed-94d6-4a1c-afaa-e3af1fac0366",
        "id": "vFeGfBw_5kEL"
      },
      "source": [
        "macro_roc_auc_ovo = roc_auc_score(valid.label.tolist(), proba_list, multi_class=\"ovo\", average=\"macro\")\n",
        "weighted_roc_auc_ovo = roc_auc_score(valid.label.tolist(), proba_list, multi_class=\"ovo\", average=\"weighted\")\n",
        "macro_roc_auc_ovr = roc_auc_score(valid.label.tolist(), proba_list, multi_class=\"ovr\", average=\"macro\")\n",
        "weighted_roc_auc_ovr = roc_auc_score(valid.label.tolist(), proba_list, multi_class=\"ovr\", average=\"weighted\")\n",
        "print(\n",
        "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
        ")\n",
        "print()\n",
        "print(\n",
        "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One ROC AUC scores:\n",
            "0.714638 (macro),\n",
            "0.730487 (weighted by prevalence)\n",
            "\n",
            "One-vs-Rest ROC AUC scores:\n",
            "0.741997 (macro),\n",
            "0.755856 (weighted by prevalence)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB-wRTCU5kEL"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW9tuOZ55kEL"
      },
      "source": [
        "# probabilities\n",
        "df_prob = pd.DataFrame(pred_proba)\n",
        "df_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9iyfkil5kEM"
      },
      "source": [
        "# roc curve for classes\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh ={}\n",
        "\n",
        "n_class = 3\n",
        "\n",
        "for i in range(n_class):    \n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(valid.label, df_prob[i], pos_label=i)\n",
        "    \n",
        "# plotting    \n",
        "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
        "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
        "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
        "plt.title('Multiclass ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Multiclass ROC',dpi=300);  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC9lv2G45kEM"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_loss(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq4J8TA45kEM"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_acc(5)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj70GFZLtbnv"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, embedding_size, output_size, weights, bidirectional):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.embedding.weight = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "        self.GRU = nn.GRU(input_size=self.embedding_size,\n",
        "                           hidden_size=self.hidden_size,\n",
        "                           #dropout=dropout,\n",
        "                           num_layers=self.num_layers, \n",
        "                           bidirectional=self.bidirectional,\n",
        "                           batch_first=True\n",
        "                           )\n",
        "        \n",
        "        if self.bidirectional: \n",
        "          self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        #x = x.reshape(x.shape[1], x.shape[0], x.shape[2])\n",
        "\n",
        "        if self.bidirectional:\n",
        "            h = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        else:\n",
        "            h = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        out, (ht, ct) = self.GRU(x, h)\n",
        "         \n",
        "        if self.bidirectional: \n",
        "          out = out.contiguous().view(-1, self.hidden_size*2)\n",
        "        else:\n",
        "          out = out.contiguous().view(-1, self.hidden_size)\n",
        "          \n",
        "        out = self.fc(out)   \n",
        "         \n",
        "        #Keep only the hidden representation of the last item of the sequence as the representative of the sample.\n",
        "        out = out.view(x.size(0), -1, self.output_size)\n",
        "        out = out[:, -1, :]\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "YHj0QzVytyXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHIH2-z6tyXI"
      },
      "outputs": [],
      "source": [
        "#Define layer sizes\n",
        "vocab_size = pretrained_embeddings.shape[0]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "embedding_size = pretrained_embeddings.shape[1]\n",
        "output_size = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer\n",
        "model = GRU(vocab_size, hidden_size, num_layers, embedding_size, output_size, pretrained_embeddings, False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.01)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP2j4KMetyXI"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd0aDrJVtyXI"
      },
      "outputs": [],
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "clip = 5\n",
        "\n",
        "for epoch in range(10):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  pred_proba = []\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for batch in train_iterator:  # for every batch\n",
        "    if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "      y_pred = model(batch.tweet)\n",
        "      loss = criterion(y_pred, batch.label)\n",
        "      batch_losses.append(loss)\n",
        "      #Delete previously stored gradients\n",
        "      optimizer.zero_grad()\n",
        "      #Perform backpropagation starting from the loss calculated in this epoch\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #Update model's weights based on the gradients calculated during backprop\n",
        "      optimizer.step()\n",
        "\n",
        "      # Total number of labels\n",
        "      total += batch.label.size(0)\n",
        "      # Total correct predictions\n",
        "      _,pred_label = torch.max(y_pred, dim = 1)\n",
        "      batch_acc += (pred_label == batch.label).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "    for batch in valid_iterator:\n",
        "      if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "        y_dev_pred = model(batch.tweet)\n",
        "        prob = F.softmax(y_dev_pred, dim=1)   # probability that an instance belogs to each class\n",
        "        #print(prob.shape)\n",
        "        for i in prob:\n",
        "          pred_proba.append(i.tolist())\n",
        "        loss_dev = criterion(y_dev_pred, batch.label)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += batch.label.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        batch_acc_dev += (pred_label == batch.label).sum()\n",
        "\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_iterator)\n",
        "  valid_loss = sum(batch_losses_dev)/len(valid_iterator)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHPPRYbdkTLJ"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, valid_iter = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), sort_key=lambda x: len(x.tweet),\n",
        "    batch_size=len(TEXT.vocab), shuffle=True)"
      ],
      "metadata": {
        "id": "XNPsqDfeAFC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "for batch in valid_iter:\n",
        "  true = batch.label\n",
        "  pred = model(batch.tweet).squeeze(1)\n",
        "  after_train = criterion(pred, true) \n",
        "  print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "id": "8pOpNYctAFC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,pred_label = torch.max(pred, dim = 1)"
      ],
      "metadata": {
        "id": "ax-feOgBT2GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(true.shape)\n",
        "print(pred_label.shape)\n"
      ],
      "metadata": {
        "id": "wyI6F6Oh3Tkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyaNtxfgn2fj"
      },
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "df = pd.DataFrame({'true':true})\n",
        "df2 = pd.DataFrame({'pred':pred_label})\n",
        "cm = confusion_matrix(true, pred_label)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR4Ze3Mn9lj"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(true, pred_label, average='micro'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Tp1qZzn63i"
      },
      "source": [
        "print(classification_report(true, pred_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob = F.softmax(pred, dim=1)\n",
        "pred_proba = []\n",
        "for i in prob:\n",
        "  pred_proba.append(i.tolist())"
      ],
      "metadata": {
        "id": "D5OWhpS9fOpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JQrPlYm5Fll"
      },
      "source": [
        "macro_roc_auc_ovo = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
        "weighted_roc_auc_ovo = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovo\", average=\"weighted\")\n",
        "macro_roc_auc_ovr = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
        "weighted_roc_auc_ovr = roc_auc_score(true.tolist(), pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
        "print(\n",
        "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
        ")\n",
        "print()\n",
        "print(\n",
        "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JucQf53RkPau"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6IVDtwo5N4h"
      },
      "source": [
        "# probabilities\n",
        "df_prob = pd.DataFrame(pred_proba)\n",
        "df_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GH0cd85N4h"
      },
      "source": [
        "# roc curve for classes\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh ={}\n",
        "\n",
        "n_class = 3\n",
        "\n",
        "for i in range(n_class):    \n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(true, df_prob[i], pos_label=i)\n",
        "    \n",
        "# plotting    \n",
        "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
        "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
        "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
        "plt.title('Multiclass ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Multiclass ROC',dpi=300);  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foSvkW0ytpxF"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_loss(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cJojWzkNQs"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_acc(10)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}