{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vaccine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW34__zUBaFL"
      },
      "source": [
        "# Vaccine Sentiment Classification\n",
        "*by Nefeli Tavoulari*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnk1un7nBfNR"
      },
      "source": [
        "#### In this notebook I classify tweets as Neutral, Pro-vax or Anti-vax."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOXT2nsK1kOq"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8wlD1VRC3F",
        "outputId": "1a099a66-9cf6-49af-8974-20c119b1f0bc"
      },
      "source": [
        "!pip install -U torch==1.8.0 torchtext==0.9.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 12 kB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.62.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0 torchtext-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYnNIsloBipg"
      },
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB8j3615BTwM",
        "outputId": "0dce5372-c5f0-47d1-a8fc-2b4f1581335c"
      },
      "source": [
        "%matplotlib inline\n",
        "import io\n",
        "import re\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "import re\n",
        "import csv\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.legacy import data   \n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, roc_curve, roc_auc_score\n",
        "from sklearn.metrics import roc_curve, accuracy_score, mean_absolute_error\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwQ1dAaDBrKg"
      },
      "source": [
        "## Upload dataset - Create and Clean dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mBmlpIlBt84",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "cb789184-fc2b-419f-afcb-75bdfce8d58f"
      },
      "source": [
        "upload_train = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df351821-94a9-4fce-9275-65cbe67c00e5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df351821-94a9-4fce-9275-65cbe67c00e5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_train.csv to vs_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqzdiqaTBv_E",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "8ac68d06-5392-4710-8c0b-8c746d52a3fe"
      },
      "source": [
        "upload_dev = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2e36beda-c850-4614-8092-75e205f1bfde\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2e36beda-c850-4614-8092-75e205f1bfde\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving vs_dev.csv to vs_dev.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crl8Sc9YByK9"
      },
      "source": [
        "train_df = pd.read_csv(io.BytesIO(upload_train['vs_train.csv']))\n",
        "dev_df = pd.read_csv(io.BytesIO(upload_dev['vs_dev.csv']))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "train_df.drop_duplicates(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "dev_df.dropna(subset = [\"tweet\"], inplace=True)\n",
        "\n",
        "train_df.drop(['Unnamed: 0'], axis = 1, inplace = True) \n",
        "dev_df.drop(['Unnamed: 0'], axis = 1, inplace = True) "
      ],
      "metadata": {
        "id": "MLSekm-spl7O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKStHo66Bz8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cfcb8b-25dc-4c8a-c8a8-21ab047f6b68"
      },
      "source": [
        "print(train_df) # training data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   tweet  label\n",
            "0      Sip N Shop Come thru right now #Marjais #Popul...      0\n",
            "1      I don't know about you but My family and I wil...      1\n",
            "2      @MSignorile Immunizations should be mandatory....      2\n",
            "3      President Obama spoke in favor of vaccination ...      0\n",
            "4      \"@myfoxla: Arizona monitoring hundreds for mea...      0\n",
            "...                                                  ...    ...\n",
            "15971  @Salon if u believe the anti-vax nutcases caus...      1\n",
            "15972  How do you feel about parents who don't #vacci...      0\n",
            "15973  70 Preschoolers Tested for Measles in Simi Val...      0\n",
            "15974  Finance Minister: Budget offers room to procur...      0\n",
            "15975  Are you up to date on vaccines? Take CDC’s vac...      2\n",
            "\n",
            "[15881 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W3hygNmB05X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "061f0896-7c93-4ae1-ad96-24a534c5a412"
      },
      "source": [
        "print(dev_df) # validation data"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  tweet  label\n",
            "0     @user They had a massive surge in with covid d...      1\n",
            "1     Required vaccines for school: Parents and guar...      0\n",
            "2     “@KCStar: Two more Johnson County children hav...      0\n",
            "3     NV can do better. Which states are the best (a...      2\n",
            "4     Nothing like killing ourselves w/ our own fear...      2\n",
            "...                                                 ...    ...\n",
            "2277  RT @abc7: Number of measles cases reported in ...      0\n",
            "2278  Evidence points to the idea that \"measles affe...      0\n",
            "2279  Where's @SavedYouAClick \"@voxdotcom: Why you s...      2\n",
            "2280  Some of my favorite people have autism. If tha...      2\n",
            "2281  Coronavirus: The married couple behind the suc...      0\n",
            "\n",
            "[2282 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrknN4jRbeN6"
      },
      "source": [
        "## Use Glove Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True, sequential=True, tokenize=\"spacy\", batch_first=True)\n",
        "LABEL = data.LabelField(dtype = torch.long, sequential=False)"
      ],
      "metadata": {
        "id": "kzTe1JsAWaZn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train.csv\", index=False)\n",
        "dev_df.to_csv(\"valid.csv\", index=False)\n",
        "\n",
        "train_data, valid_data = data.TabularDataset.splits(\n",
        "    path=\"\", train=\"train.csv\", \n",
        "    validation=\"valid.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('tweet', TEXT), ('label', LABEL)]\n",
        ")\n",
        "\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maMN_J5LoYVt",
        "outputId": "d9930806-8c3b-4726-b1f6-6a04f2705890"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 15881\n",
            "Number of validation examples: 2282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data, vectors='glove.twitter.27B.25d', max_size=20000, min_freq=5)\n",
        "\n",
        "# get the vocab instance\n",
        "vocab = TEXT.vocab\n",
        "vocab.vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgpUUassov5r",
        "outputId": "d59a63a6-35fb-497c-f1c6-b9e001e04d16"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.twitter.27B.zip: 1.52GB [05:13, 4.85MB/s]                            \n",
            "100%|█████████▉| 1193513/1193514 [00:25<00:00, 47127.62it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.6959, -1.1469, -0.4180,  ..., -0.6788,  0.7061,  0.4083],\n",
              "        ...,\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.freqs.most_common(10) # seems right"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3JSXRCyoRF-",
        "outputId": "346ebb4c-4d55-49c7-f418-21a88f83bb44"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 11333),\n",
              " ('#', 9475),\n",
              " ('the', 8671),\n",
              " ('to', 6866),\n",
              " (',', 6630),\n",
              " ('vaccine', 5080),\n",
              " ('a', 5003),\n",
              " (':', 4629),\n",
              " ('measles', 4438),\n",
              " ('of', 4320)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL.build_vocab(train_data)\n",
        "vocab_label = LABEL.vocab\n",
        "print(\"Size of LABEL vocabulary:\",len(vocab_label))\n",
        "vocab_label.freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKw9ZjuRt80S",
        "outputId": "f88aed04-28fe-4810-cb56-ad5f84d8cfec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of LABEL vocabulary: 3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 7385, '1': 2070, '2': 6426})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxUsiH2NuK46",
        "outputId": "bf31d786-5757-4963-85e6-0424fae754c7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 4596\n",
            "Unique tokens in LABEL vocabulary: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Batch Iterator"
      ],
      "metadata": {
        "id": "1INLU0MPuOxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), sort_key=lambda x: len(x.tweet),\n",
        "    batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "LABEL.vocab.freqs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPMosIgtZdXs",
        "outputId": "d21a0a8b-d41a-4c83-b714-4bcb53f9e336"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 7385, '1': 2070, '2': 6426})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "pretrained_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVUxUElhvbJZ",
        "outputId": "0ab6e4d2-dc06-4d9b-c64e-68df206bf58f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4596, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBYKnos9o6qR"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, embedding_size, output_size, weights, bidirectional):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.embedding.weight = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_size,\n",
        "                           hidden_size=self.hidden_size,\n",
        "                           #dropout=dropout,\n",
        "                           num_layers=self.num_layers, \n",
        "                           bidirectional=self.bidirectional,\n",
        "                           batch_first=True\n",
        "                           )\n",
        "        \n",
        "        if self.bidirectional: \n",
        "          self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        #x = x.reshape(x.shape[1], x.shape[0], x.shape[2])\n",
        "\n",
        "        if self.bidirectional:\n",
        "            h = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "            c = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        else:\n",
        "            h = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "            c = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        out, (ht, ct) = self.lstm(x, (h, c))\n",
        "         \n",
        "        if self.bidirectional: \n",
        "          out = out.contiguous().view(-1, self.hidden_size*2)\n",
        "        else:\n",
        "          out = out.contiguous().view(-1, self.hidden_size)\n",
        "          \n",
        "        out = self.fc(out)   \n",
        "         \n",
        "        #Keep only the hidden representation of the last item of the sequence as the representative of the sample.\n",
        "        out = out.view(x.size(0), -1, self.output_size)\n",
        "        out = out[:, -1, :]\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "mIBXht8xCzSr"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bwsrdCGKb_j5"
      },
      "outputs": [],
      "source": [
        "#Define layer sizes\n",
        "vocab_size = pretrained_embeddings.shape[0]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "embedding_size = pretrained_embeddings.shape[1]\n",
        "output_size = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer\n",
        "model = LSTM(vocab_size, hidden_size, num_layers, embedding_size, output_size, pretrained_embeddings, False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.01)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "E9gQg2lXb_kF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317958e5-2189-4383-9745-29f9c0fd9ac3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(4596, 25)\n",
              "  (lstm): LSTM(25, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0h9hsKHAb_kH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "a2cd458f-c205-4eaa-98e4-21aff1d75034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: | Train Loss = 0.81124 | Train Accuracy = 0.63143 | Validation Loss = 0.95096 | Validation Accuracy = 0.49062 \n",
            "Epoch   1: | Train Loss = 0.80164 | Train Accuracy = 0.63552 | Validation Loss = 0.94475 | Validation Accuracy = 0.49732 \n",
            "Epoch   2: | Train Loss = 0.79583 | Train Accuracy = 0.64025 | Validation Loss = 0.95699 | Validation Accuracy = 0.46830 \n",
            "Epoch   3: | Train Loss = 0.79223 | Train Accuracy = 0.64157 | Validation Loss = 0.93259 | Validation Accuracy = 0.49866 \n",
            "Epoch   4: | Train Loss = 0.78851 | Train Accuracy = 0.64252 | Validation Loss = 0.91082 | Validation Accuracy = 0.54018 \n",
            "Epoch   5: | Train Loss = 0.78153 | Train Accuracy = 0.64636 | Validation Loss = 0.89146 | Validation Accuracy = 0.56429 \n",
            "Epoch   6: | Train Loss = 0.78004 | Train Accuracy = 0.65089 | Validation Loss = 0.85658 | Validation Accuracy = 0.59955 \n",
            "Epoch   7: | Train Loss = 0.77650 | Train Accuracy = 0.65026 | Validation Loss = 0.85843 | Validation Accuracy = 0.59330 \n",
            "Epoch   8: | Train Loss = 0.77233 | Train Accuracy = 0.65228 | Validation Loss = 0.86353 | Validation Accuracy = 0.57098 \n",
            "Epoch   9: | Train Loss = 0.76802 | Train Accuracy = 0.65562 | Validation Loss = 0.85418 | Validation Accuracy = 0.58839 \n",
            "Epoch  10: | Train Loss = 0.76959 | Train Accuracy = 0.65537 | Validation Loss = 0.84661 | Validation Accuracy = 0.59509 \n",
            "Epoch  11: | Train Loss = 0.75972 | Train Accuracy = 0.65883 | Validation Loss = 0.81802 | Validation Accuracy = 0.60312 \n",
            "Epoch  12: | Train Loss = 0.76032 | Train Accuracy = 0.65726 | Validation Loss = 0.84911 | Validation Accuracy = 0.55580 \n",
            "Epoch  13: | Train Loss = 0.75711 | Train Accuracy = 0.66305 | Validation Loss = 0.82364 | Validation Accuracy = 0.60580 \n",
            "Epoch  14: | Train Loss = 0.75645 | Train Accuracy = 0.66274 | Validation Loss = 0.84921 | Validation Accuracy = 0.55223 \n",
            "Epoch  15: | Train Loss = 0.75433 | Train Accuracy = 0.66394 | Validation Loss = 0.86020 | Validation Accuracy = 0.54554 \n",
            "Epoch  16: | Train Loss = 0.74850 | Train Accuracy = 0.66608 | Validation Loss = 0.85314 | Validation Accuracy = 0.55536 \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7dacd0143fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for every batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       \u001b[0;31m#print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-a2d20a12f35e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 662\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "clip = 5\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  pred_proba = []\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for batch in train_iterator:  # for every batch\n",
        "    if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "      y_pred = model(batch.tweet)\n",
        "      #print(y_pred)\n",
        "      loss = criterion(y_pred, batch.label)\n",
        "      batch_losses.append(loss)\n",
        "      #Delete previously stored gradients\n",
        "      optimizer.zero_grad()\n",
        "      #Perform backpropagation starting from the loss calculated in this epoch\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #Update model's weights based on the gradients calculated during backprop\n",
        "      optimizer.step()\n",
        "\n",
        "      # Total number of labels\n",
        "      total += batch.label.size(0)\n",
        "      # Total correct predictions\n",
        "      _,pred_label = torch.max(y_pred, dim = 1)\n",
        "      batch_acc += (pred_label == batch.label).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "    for batch in valid_iterator:\n",
        "      if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "        y_dev_pred = model(batch.tweet)\n",
        "        prob = F.softmax(y_dev_pred, dim=1)   # probability that an instance belogs to each class\n",
        "        #print(prob.shape)\n",
        "        for i in prob:\n",
        "          pred_proba.append(i.tolist())\n",
        "        loss_dev = criterion(y_dev_pred, batch.label)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += batch.label.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        batch_acc_dev += (pred_label == batch.label).sum()\n",
        "\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_iterator)\n",
        "  valid_loss = sum(batch_losses_dev)/len(valid_iterator)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj70GFZLtbnv"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_size, num_layers, embedding_size, output_size, weights, bidirectional):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.embedding.weight = nn.Parameter(weights, requires_grad=False)\n",
        "\n",
        "        self.GRU = nn.GRU(input_size=self.embedding_size,\n",
        "                           hidden_size=self.hidden_size,\n",
        "                           #dropout=dropout,\n",
        "                           num_layers=self.num_layers, \n",
        "                           bidirectional=self.bidirectional,\n",
        "                           batch_first=True\n",
        "                           )\n",
        "        \n",
        "        if self.bidirectional: \n",
        "          self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "        else:\n",
        "          self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        #x = x.reshape(x.shape[1], x.shape[0], x.shape[2])\n",
        "\n",
        "        if self.bidirectional:\n",
        "            h = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        else:\n",
        "            h = torch.zeros((self.num_layers, x.size(0), self.hidden_size))\n",
        "\n",
        "        out, (ht, ct) = self.GRU(x, (h, c))\n",
        "         \n",
        "        if self.bidirectional: \n",
        "          out = out.contiguous().view(-1, self.hidden_size*2)\n",
        "        else:\n",
        "          out = out.contiguous().view(-1, self.hidden_size)\n",
        "          \n",
        "        out = self.fc(out)   \n",
        "         \n",
        "        #Keep only the hidden representation of the last item of the sequence as the representative of the sample.\n",
        "        out = out.view(x.size(0), -1, self.output_size)\n",
        "        out = out[:, -1, :]\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "YHj0QzVytyXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHIH2-z6tyXI"
      },
      "outputs": [],
      "source": [
        "#Define layer sizes\n",
        "vocab_size = pretrained_embeddings.shape[0]\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "embedding_size = pretrained_embeddings.shape[1]\n",
        "output_size = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer\n",
        "model = GRU(vocab_size, hidden_size, num_layers, embedding_size, output_size, pretrained_embeddings, False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.01)\n",
        "#optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317958e5-2189-4383-9745-29f9c0fd9ac3",
        "id": "NP2j4KMetyXI"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (embedding): Embedding(4596, 25)\n",
              "  (lstm): LSTM(25, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd0aDrJVtyXI"
      },
      "outputs": [],
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "clip = 5\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  pred_proba = []\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for batch in train_iterator:  # for every batch\n",
        "    if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "      y_pred = model(batch.tweet)\n",
        "      #print(y_pred)\n",
        "      loss = criterion(y_pred, batch.label)\n",
        "      batch_losses.append(loss)\n",
        "      #Delete previously stored gradients\n",
        "      optimizer.zero_grad()\n",
        "      #Perform backpropagation starting from the loss calculated in this epoch\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "      #Update model's weights based on the gradients calculated during backprop\n",
        "      optimizer.step()\n",
        "\n",
        "      # Total number of labels\n",
        "      total += batch.label.size(0)\n",
        "      # Total correct predictions\n",
        "      _,pred_label = torch.max(y_pred, dim = 1)\n",
        "      batch_acc += (pred_label == batch.label).sum()\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "    for batch in valid_iterator:\n",
        "      if batch.tweet.shape[0] == BATCH_SIZE:\n",
        "        y_dev_pred = model(batch.tweet)\n",
        "        prob = F.softmax(y_dev_pred, dim=1)   # probability that an instance belogs to each class\n",
        "        #print(prob.shape)\n",
        "        for i in prob:\n",
        "          pred_proba.append(i.tolist())\n",
        "        loss_dev = criterion(y_dev_pred, batch.label)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += batch.label.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        batch_acc_dev += (pred_label == batch.label).sum()\n",
        "\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_iterator)\n",
        "  valid_loss = sum(batch_losses_dev)/len(valid_iterator)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHPPRYbdkTLJ"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "true = y_dev\n",
        "pred = model(x_dev).squeeze(1)\n",
        "after_train = criterion(pred, true) \n",
        "print('Test loss after Training' , after_train.item())"
      ],
      "metadata": {
        "id": "_VhYsUjBKHGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_,pred_label = torch.max(pred, dim = 1)"
      ],
      "metadata": {
        "id": "ax-feOgBT2GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyaNtxfgn2fj"
      },
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "df = pd.DataFrame({'true':true})\n",
        "df2 = pd.DataFrame({'pred':pred})\n",
        "cm = confusion_matrix(true, pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pR4Ze3Mn9lj"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(true, pred, average='micro'))\n",
        "print()\n",
        "print(\"Precision-Recall-F1 - Test Data :\")\n",
        "print(precision_recall_fscore_support(true_dev, pred_dev, average='micro'))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4Tp1qZzn63i"
      },
      "source": [
        "print(classification_report(true, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWCY94YTNCtF"
      },
      "source": [
        "macro_roc_auc_ovo = roc_auc_score(true_dev, pred_proba, multi_class=\"ovo\", average=\"macro\")\n",
        "weighted_roc_auc_ovo = roc_auc_score(true_dev, pred_proba, multi_class=\"ovo\", average=\"weighted\")\n",
        "macro_roc_auc_ovr = roc_auc_score(true_dev, pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
        "weighted_roc_auc_ovr = roc_auc_score(true_dev, pred_proba, multi_class=\"ovr\", average=\"weighted\")\n",
        "print(\n",
        "    \"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovo, weighted_roc_auc_ovo)\n",
        ")\n",
        "print()\n",
        "print(\n",
        "    \"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
        "    \"(weighted by prevalence)\".format(macro_roc_auc_ovr, weighted_roc_auc_ovr)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JucQf53RkPau"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdlP0xdcU_p_"
      },
      "source": [
        "# probabilities\n",
        "df_prob = pd.DataFrame(pred_proba)\n",
        "df_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHGuBmfJqWBm"
      },
      "source": [
        "# roc curve for classes\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh ={}\n",
        "\n",
        "n_class = 3\n",
        "\n",
        "for i in range(n_class):    \n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(true_dev, df_prob[i], pos_label=i)\n",
        "    \n",
        "# plotting    \n",
        "plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n",
        "plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n",
        "plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n",
        "plt.title('Multiclass ROC curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive rate')\n",
        "plt.legend(loc='best')\n",
        "plt.savefig('Multiclass ROC',dpi=300);  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foSvkW0ytpxF"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_loss(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71cJojWzkNQs"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "\n",
        "plot_graph_acc(100)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GZAQd93xYXE"
      },
      "source": [
        "## Second Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmu-PutrxYXG"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.input_dim = input_dim\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)#.requires_grad_()\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim)#.requires_grad_() \n",
        "        out = self.embedding(x)\n",
        "        out, (hn, cn) = self.lstm(out, h0, c0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsnnrIHHxYXG"
      },
      "source": [
        "#Define layer sizes\n",
        "input_dim = x.shape[1]\n",
        "hidden_dim = 128\n",
        "num_layers = 4\n",
        "output_dim = 3\n",
        "\n",
        "#Define Hyperparameters\n",
        "learning_rate = 1e-4\n",
        "\n",
        "#Initialize model, optimizer, loss function\n",
        "model = LSTM(input_dim, hidden_dim, num_layers, output_dim)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQgFSLqbxYXH"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9TQMjNcxYXH"
      },
      "source": [
        "epoch_loss = []\n",
        "epoch_loss_dev = []\n",
        "epoch_acc = []\n",
        "epoch_acc_dev = []\n",
        "\n",
        "for epoch in range(100):\n",
        "\n",
        "  batch_losses = []\n",
        "  batch_acc = 0\n",
        "  total = 0\n",
        "  total_dev = 0\n",
        "  loss = 0\n",
        "  pred = []\n",
        "  true = []\n",
        "  pred_dev = []\n",
        "  true_dev = []\n",
        "\n",
        "  # training\n",
        "  model.train()\n",
        "  for x_batch, y_batch in train_dataloader:  # for every batch\n",
        "    print(x_batch.shape)\n",
        "    y_pred = model(x_batch).squeeze(1)\n",
        "    loss = loss_func(y_pred, y_batch)\n",
        "    batch_losses.append(loss)\n",
        "    #Delete previously stored gradients\n",
        "    optimizer.zero_grad()\n",
        "    #Perform backpropagation starting from the loss calculated in this epoch\n",
        "    loss.backward()\n",
        "    #Update model's weights based on the gradients calculated during backprop\n",
        "    optimizer.step()\n",
        "\n",
        "    # Total number of labels\n",
        "    total += y_batch.size(0)\n",
        "    # Total correct predictions\n",
        "    _,pred_label = torch.max(y_pred, dim = 1)\n",
        "    batch_acc += (pred_label == y_batch).sum()\n",
        "    for i in pred_label:\n",
        "      pred.append(i)\n",
        "    for i in y_batch:\n",
        "      true.append(i.item())\n",
        "\n",
        "  # validation    \n",
        "  with torch.no_grad():\n",
        "    batch_losses_dev = []\n",
        "    batch_acc_dev = 0\n",
        "    model.eval()\n",
        "\n",
        "    for x_batch, y_batch in dev_dataloader:\n",
        "        y_dev_pred = model(x_batch)\n",
        "        loss_dev = loss_func(y_dev_pred, y_batch)\n",
        "        batch_losses_dev.append(loss_dev)\n",
        "        # number of labels\n",
        "        total_dev += y_batch.size(0)\n",
        "        # correct predictions\n",
        "        _,pred_label = torch.max(y_dev_pred, dim = 1)  # get max probability\n",
        "        batch_acc_dev += (pred_label == y_batch).sum()\n",
        "        for i in pred_label:\n",
        "          pred_dev.append(i)\n",
        "        for i in y_batch:\n",
        "          true_dev.append(i.item())\n",
        "\n",
        "\n",
        "  accuracy = batch_acc/total\n",
        "  accuracy_dev = batch_acc_dev/total_dev\n",
        "\n",
        "  train_loss = sum(batch_losses)/len(train_dataloader)\n",
        "  valid_loss = sum(batch_losses_dev)/len(dev_dataloader)\n",
        "\n",
        "  epoch_loss.append(train_loss)\n",
        "  epoch_loss_dev.append(valid_loss)\n",
        "  epoch_acc.append(accuracy)\n",
        "  epoch_acc_dev.append(accuracy_dev)\n",
        "\n",
        "  print(f\"Epoch {epoch:3}: | Train Loss = {train_loss:.5f} | Train Accuracy = {accuracy:.5f} | Validation Loss = {valid_loss:.5f} | Validation Accuracy = {accuracy_dev:.5f} \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkg036AAxYXI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPE7KRl7xYXI"
      },
      "source": [
        "target_names = ['neutral', 'anti-vax', 'pro-vax']\n",
        "df = pd.DataFrame({'true':true})\n",
        "df2 = pd.DataFrame({'pred':pred})\n",
        "cm = confusion_matrix(true, pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
        "disp.plot()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1AlvPI2xYXI"
      },
      "source": [
        "print(\"Precision-Recall-F1 - Training Data :\")\n",
        "print(precision_recall_fscore_support(true, pred, average='micro'))\n",
        "print()\n",
        "print(\"Precision-Recall-F1 - Test Data :\")\n",
        "print(precision_recall_fscore_support(true_dev, pred_dev, average='micro'))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZyYICtxYXJ"
      },
      "source": [
        "print(classification_report(true, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SL-_dIexYXJ"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAvYEyVoxYXK"
      },
      "source": [
        "def plot_graph_loss(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Loss\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_loss, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_loss_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('loss', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "plot_graph_loss(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGmfTebrxYXK"
      },
      "source": [
        "def plot_graph_acc(epochs):\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    plt.title(\"Train/Validation Accuracy\")\n",
        "    plt.plot(list(np.arange(epochs) + 1) , epoch_acc, label='train')\n",
        "    plt.plot(list(np.arange(epochs) + 1), epoch_acc_dev, label='validation')\n",
        "    plt.xlabel('num_epochs', fontsize=12)\n",
        "    plt.ylabel('accuracy', fontsize=12)\n",
        "    plt.legend(['train', 'validation']);\n",
        "plot_graph_acc(100)    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}